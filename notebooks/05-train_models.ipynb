{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from src.metric import amex_metric\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"05\"\n",
    "PATH = \"../data/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Woe_balanced dataframe\n",
    "train = pd.read_parquet(PATH + \"train_woebalanced_20bins.parquet\")\n",
    "train = train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<458913x50 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5048043 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit_transform(train[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after engineering (458913, 918)\n"
     ]
    }
   ],
   "source": [
    "train = train.drop('target', axis=1)\n",
    "\n",
    "def process_and_feature_engineer(df):\n",
    "    # FEATURE ENGINEERING FROM\n",
    "    # https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
    "    all_cols = [c for c in list(df.columns) if c not in [\"customer_ID\", \"S_2\"]]\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    num_features = [col for col in all_cols if col not in cat_features]\n",
    "\n",
    "    test_num_agg = df.groupby(\"customer_ID\")[num_features].agg(\n",
    "        [\"mean\", \"std\", \"min\", \"max\", \"last\"]\n",
    "    )\n",
    "    test_num_agg.columns = [\"_\".join(x) for x in test_num_agg.columns]\n",
    "\n",
    "    test_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg(\n",
    "        [\"count\", \"last\", \"nunique\"]\n",
    "    )\n",
    "    test_cat_agg.columns = [\"_\".join(x) for x in test_cat_agg.columns]\n",
    "\n",
    "    df = pd.concat([test_num_agg, test_cat_agg], axis=1)\n",
    "    del test_num_agg, test_cat_agg\n",
    "    print(\"shape after engineering\", df.shape)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = process_and_feature_engineer(train)\n",
    "\n",
    "labels = pd.read_csv(\"../data/raw/train_labels.csv\")\n",
    "labels = labels.set_index(\"customer_ID\")\n",
    "train = train.merge(labels, left_index=True, right_index=True, how='left')\n",
    "\n",
    "train = train.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv_features = pd.read_csv(\"../reports/iv_features_20bins.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURES = iv_features[\"useful\"].to_list()\n",
    "FEATURES.remove(\"target\")\n",
    "while np.NaN in FEATURES: FEATURES.remove(np.NaN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "\n",
    "xgb_params = {\n",
    "    \"max_depth\": 4,\n",
    "    \"learning_rate\": 0.045,\n",
    "    \"max_delta_step\": 3,\n",
    "    \"subsample\": 0.7,\n",
    "    \"sampling_method\": \"gradient_based\",\n",
    "    \"tree_method\": \"gpu_hist\",\n",
    "    \"colsample_bytree\": 0.6,\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"predictor\": \"gpu_predictor\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting MLFlow\n",
    "experiment_name = \"XGBoost - WoE Balanced + IV Balanced\"\n",
    "try:\n",
    "    exp_id = mlflow.create_experiment(name=experiment_name)\n",
    "except Exception as e:\n",
    "    exp_id = mlflow.get_experiment_by_name(experiment_name).experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = train.columns.to_list()\n",
    "FEATURES.remove(\"target\")\n",
    "FEATURES=FEATURES[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/03 14:37:51 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of xgboost. If you encounter errors during autologging, try upgrading / downgrading xgboost to a supported version, or try upgrading MLflow.\n",
      "2022/11/03 14:37:51 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
      "2022/11/03 14:37:51 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
      "2022/11/03 14:37:51 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "### Train size 367130 Valid size 91783\n",
      "### Training with 100% fold data...\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/03 14:37:58 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd92b0cf16d154174bb93b2bbb6fe9d94', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current xgboost workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.66504\ttest-logloss:0.66503\n",
      "[100]\ttrain-logloss:0.24432\ttest-logloss:0.24563\n",
      "[200]\ttrain-logloss:0.22996\ttest-logloss:0.23298\n",
      "[300]\ttrain-logloss:0.22461\ttest-logloss:0.22916\n",
      "[400]\ttrain-logloss:0.22133\ttest-logloss:0.22734\n",
      "[500]\ttrain-logloss:0.21884\ttest-logloss:0.22616\n",
      "[600]\ttrain-logloss:0.21683\ttest-logloss:0.22539\n",
      "[700]\ttrain-logloss:0.21499\ttest-logloss:0.22481\n",
      "[800]\ttrain-logloss:0.21333\ttest-logloss:0.22438\n",
      "[900]\ttrain-logloss:0.21178\ttest-logloss:0.22400\n",
      "[1000]\ttrain-logloss:0.21031\ttest-logloss:0.22372\n",
      "[1100]\ttrain-logloss:0.20896\ttest-logloss:0.22348\n",
      "[1200]\ttrain-logloss:0.20769\ttest-logloss:0.22327\n",
      "[1300]\ttrain-logloss:0.20648\ttest-logloss:0.22315\n",
      "[1400]\ttrain-logloss:0.20530\ttest-logloss:0.22312\n",
      "[1500]\ttrain-logloss:0.20416\ttest-logloss:0.22303\n",
      "[1600]\ttrain-logloss:0.20299\ttest-logloss:0.22294\n",
      "[1700]\ttrain-logloss:0.20190\ttest-logloss:0.22291\n",
      "[1800]\ttrain-logloss:0.20080\ttest-logloss:0.22287\n",
      "[1900]\ttrain-logloss:0.19971\ttest-logloss:0.22287\n",
      "[1989]\ttrain-logloss:0.19882\ttest-logloss:0.22290\n",
      "Kaggle Metric= 0.7850490740955252 \n",
      "\n",
      "#########################\n",
      "### Fold 2\n",
      "### Train size 367130 Valid size 91783\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "[0]\ttrain-logloss:0.66513\ttest-logloss:0.66510\n",
      "[100]\ttrain-logloss:0.24442\ttest-logloss:0.24564\n",
      "[200]\ttrain-logloss:0.22996\ttest-logloss:0.23283\n",
      "[300]\ttrain-logloss:0.22459\ttest-logloss:0.22886\n",
      "[400]\ttrain-logloss:0.22131\ttest-logloss:0.22692\n",
      "[500]\ttrain-logloss:0.21884\ttest-logloss:0.22568\n",
      "[600]\ttrain-logloss:0.21683\ttest-logloss:0.22485\n",
      "[700]\ttrain-logloss:0.21500\ttest-logloss:0.22423\n",
      "[800]\ttrain-logloss:0.21334\ttest-logloss:0.22383\n",
      "[900]\ttrain-logloss:0.21176\ttest-logloss:0.22353\n",
      "[1000]\ttrain-logloss:0.21032\ttest-logloss:0.22332\n",
      "[1100]\ttrain-logloss:0.20895\ttest-logloss:0.22313\n",
      "[1200]\ttrain-logloss:0.20760\ttest-logloss:0.22292\n",
      "[1300]\ttrain-logloss:0.20636\ttest-logloss:0.22279\n",
      "[1400]\ttrain-logloss:0.20511\ttest-logloss:0.22264\n",
      "[1500]\ttrain-logloss:0.20390\ttest-logloss:0.22258\n",
      "[1600]\ttrain-logloss:0.20270\ttest-logloss:0.22247\n",
      "[1700]\ttrain-logloss:0.20154\ttest-logloss:0.22243\n",
      "[1800]\ttrain-logloss:0.20044\ttest-logloss:0.22241\n",
      "[1900]\ttrain-logloss:0.19937\ttest-logloss:0.22236\n",
      "[2000]\ttrain-logloss:0.19828\ttest-logloss:0.22237\n",
      "[2027]\ttrain-logloss:0.19799\ttest-logloss:0.22237\n",
      "Kaggle Metric= 0.7841346141990475 \n",
      "\n",
      "#########################\n",
      "### Fold 3\n",
      "### Train size 367130 Valid size 91783\n",
      "### Training with 100% fold data...\n",
      "#########################\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb#X15sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m X_valid \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39mloc[valid_idx, FEATURES]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb#X15sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m y_valid \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39mloc[valid_idx, \u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m dtrain \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39;49mDMatrix(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mdel\u001b[39;00m X_train, y_train\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:555\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m     patch_function\u001b[39m.\u001b[39mcall(call_original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     patch_function(call_original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    557\u001b[0m session\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msucceeded\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m try_log_autologging_event(\n\u001b[1;32m    560\u001b[0m     AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_patch_function_success,\n\u001b[1;32m    561\u001b[0m     session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    565\u001b[0m     kwargs,\n\u001b[1;32m    566\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/mlflow/xgboost/__init__.py:439\u001b[0m, in \u001b[0;36mautolog.<locals>.__init__\u001b[0;34m(original, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m         input_example_info \u001b[39m=\u001b[39m InputExampleInfo(error_msg\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(e))\n\u001b[1;32m    437\u001b[0m     \u001b[39msetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39minput_example_info\u001b[39m\u001b[39m\"\u001b[39m, input_example_info)\n\u001b[0;32m--> 439\u001b[0m original(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:536\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[0;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39m_og_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_og_kwargs)\n\u001b[1;32m    534\u001b[0m         \u001b[39mreturn\u001b[39;00m original_result\n\u001b[0;32m--> 536\u001b[0m \u001b[39mreturn\u001b[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:471\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[0;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    463\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    464\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_start,\n\u001b[1;32m    465\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         og_kwargs,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 471\u001b[0m     original_fn_result \u001b[39m=\u001b[39m original_fn(\u001b[39m*\u001b[39;49mog_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mog_kwargs)\n\u001b[1;32m    473\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    474\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_success,\n\u001b[1;32m    475\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    479\u001b[0m         og_kwargs,\n\u001b[1;32m    480\u001b[0m     )\n\u001b[1;32m    481\u001b[0m     \u001b[39mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:533\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[0;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[39m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[39m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[39m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[39m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[39mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[1;32m    530\u001b[0m     disable_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    531\u001b[0m     reroute_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    532\u001b[0m ):\n\u001b[0;32m--> 533\u001b[0m     original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39;49m_og_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_og_kwargs)\n\u001b[1;32m    534\u001b[0m     \u001b[39mreturn\u001b[39;00m original_result\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/xgboost/core.py:743\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    741\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 743\u001b[0m handle, feature_names, feature_types \u001b[39m=\u001b[39m dispatch_data_backend(\n\u001b[1;32m    744\u001b[0m     data,\n\u001b[1;32m    745\u001b[0m     missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[1;32m    746\u001b[0m     threads\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnthread,\n\u001b[1;32m    747\u001b[0m     feature_names\u001b[39m=\u001b[39;49mfeature_names,\n\u001b[1;32m    748\u001b[0m     feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m    749\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[1;32m    750\u001b[0m )\n\u001b[1;32m    751\u001b[0m \u001b[39massert\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39m=\u001b[39m handle\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/xgboost/data.py:957\u001b[0m, in \u001b[0;36mdispatch_data_backend\u001b[0;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_tuple(data, missing, threads, feature_names, feature_types)\n\u001b[1;32m    956\u001b[0m \u001b[39mif\u001b[39;00m _is_pandas_df(data):\n\u001b[0;32m--> 957\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_pandas_df(data, enable_categorical, missing, threads,\n\u001b[1;32m    958\u001b[0m                            feature_names, feature_types)\n\u001b[1;32m    959\u001b[0m \u001b[39mif\u001b[39;00m _is_pandas_series(data):\n\u001b[1;32m    960\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_pandas_series(\n\u001b[1;32m    961\u001b[0m         data, missing, threads, enable_categorical, feature_names, feature_types\n\u001b[1;32m    962\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/xgboost/data.py:404\u001b[0m, in \u001b[0;36m_from_pandas_df\u001b[0;34m(data, enable_categorical, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_from_pandas_df\u001b[39m(\n\u001b[1;32m    397\u001b[0m     data: DataFrame,\n\u001b[1;32m    398\u001b[0m     enable_categorical: \u001b[39mbool\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    402\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[1;32m    403\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DispatchedDataBackendReturnType:\n\u001b[0;32m--> 404\u001b[0m     data, feature_names, feature_types \u001b[39m=\u001b[39m _transform_pandas_df(\n\u001b[1;32m    405\u001b[0m         data, enable_categorical, feature_names, feature_types\n\u001b[1;32m    406\u001b[0m     )\n\u001b[1;32m    407\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/xgboost/data.py:390\u001b[0m, in \u001b[0;36m_transform_pandas_df\u001b[0;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataFrame for \u001b[39m\u001b[39m{\u001b[39;00mmeta\u001b[39m}\u001b[39;00m\u001b[39m cannot have multiple columns\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    389\u001b[0m dtype \u001b[39m=\u001b[39m meta_type \u001b[39mif\u001b[39;00m meta_type \u001b[39melse\u001b[39;00m np\u001b[39m.\u001b[39mfloat32\n\u001b[0;32m--> 390\u001b[0m arr: np\u001b[39m.\u001b[39mndarray \u001b[39m=\u001b[39m transformed\u001b[39m.\u001b[39;49mvalues\n\u001b[1;32m    391\u001b[0m \u001b[39mif\u001b[39;00m meta_type:\n\u001b[1;32m    392\u001b[0m     arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(dtype)\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/pandas/core/frame.py:10892\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m  10819\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m  10820\u001b[0m \u001b[39mReturn a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[1;32m  10821\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10889\u001b[0m \u001b[39m       ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[1;32m  10890\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m  10891\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m> 10892\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array()\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/pandas/core/internals/managers.py:1599\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1597\u001b[0m             arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1598\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1599\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1600\u001b[0m     \u001b[39m# The underlying data was copied within _interleave\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/pandas/core/internals/managers.py:1664\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1662\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1663\u001b[0m         arr \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1664\u001b[0m     result[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m arr\n\u001b[1;32m   1665\u001b[0m     itemmask[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1667\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m itemmask\u001b[39m.\u001b[39mall():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlflow.autolog()\n",
    "importances = []\n",
    "oof = []\n",
    "TRAIN_SUBSAMPLE = 1.0\n",
    "\n",
    "skf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train.target)):\n",
    "\n",
    "    if TRAIN_SUBSAMPLE < 1.0:\n",
    "        np.random.seed(42)\n",
    "        train_idx = np.random.choice(\n",
    "            train_idx, int(len(train_idx) * TRAIN_SUBSAMPLE), replace=False\n",
    "        )\n",
    "        np.random.seed(None)\n",
    "\n",
    "    print(\"#\" * 25)\n",
    "    print(\"### Fold\", fold + 1)\n",
    "    print(\"### Train size\", len(train_idx), \"Valid size\", len(valid_idx))\n",
    "    print(f\"### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...\")\n",
    "    print(\"#\" * 25)\n",
    "\n",
    "    X_train = train.loc[train_idx, FEATURES]\n",
    "    y_train = train.loc[train_idx, \"target\"]\n",
    "    X_valid = train.loc[valid_idx, FEATURES]\n",
    "    y_valid = train.loc[valid_idx, \"target\"]\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    del X_train, y_train\n",
    "    gc.collect()\n",
    "    d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "    del X_valid\n",
    "    gc.collect()\n",
    "    model = xgb.train(\n",
    "        xgb_params,\n",
    "        dtrain=dtrain,\n",
    "        evals=[(dtrain, \"train\"), (d_valid, \"test\")],\n",
    "        num_boost_round=9999,\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=100,\n",
    "    )\n",
    "\n",
    "    model.save_model(f\"../models/XGB_Version{VERSION}_fold{fold}.xgb\")\n",
    "    mlflow.xgboost.log_model(model, \"XGBClassifier\")\n",
    "\n",
    "    dd = model.get_score(importance_type=\"weight\")\n",
    "    df = pd.DataFrame({\"feature\": dd.keys(), f\"importance_{fold}\": dd.values()})\n",
    "    importances.append(df)\n",
    "\n",
    "    oof_preds = model.predict(d_valid)\n",
    "    acc = amex_metric(y_valid.values, oof_preds)\n",
    "    mlflow.log_metric(\"Kaggle Metric for XGBClassifier\", acc)\n",
    "\n",
    "    print(\"Kaggle Metric=\", acc, \"\\n\")\n",
    "\n",
    "    df = train.loc[valid_idx, [\"customer_ID\", \"target\"]].copy()\n",
    "    df[\"oof_pred\"] = oof_preds\n",
    "    oof.append(df)\n",
    "\n",
    "    del dd, df\n",
    "    del d_valid, model\n",
    "    gc.collect()\n",
    "print(\"#\" * 25)\n",
    "oof = pd.concat(oof, axis=0, ignore_index=True).set_index(\"customer_ID\")\n",
    "acc = amex_metric(oof.target.values, oof.oof_pred.values)\n",
    "print(\"OVERAL CV Kaggle Metric = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.system('systemctl poweroff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/01 16:34:53 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of xgboost. If you encounter errors during autologging, try upgrading / downgrading xgboost to a supported version, or try upgrading MLflow.\n",
      "2022/11/01 16:34:53 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
      "2022/11/01 16:34:53 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
      "2022/11/01 16:34:53 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    }
   ],
   "source": [
    "# Setting MLFlow\n",
    "experiment_name = \"RandomForest - WoE Balanced + IV Balanced\"\n",
    "try:\n",
    "    exp_id = mlflow.create_experiment(name=experiment_name)\n",
    "except Exception as e:\n",
    "    exp_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "mlflow.autolog()\n",
    "importances = []\n",
    "oof = []\n",
    "TRAIN_SUBSAMPLE = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "### Train size 367130 Valid size 91783\n",
      "### Training with 100% fold data...\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/01 16:35:45 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 0c5f9edc7c10496681cc710c08010626. Failed operations: [MlflowException(\"Changing param values is not allowed. Param with key=\\'max_depth\\' was already logged with value=\\'4\\' for run ID=\\'0c5f9edc7c10496681cc710c08010626\\'. Attempted logging new value \\'None\\'.\")]')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric= 0.5502397072824545 \n",
      "\n",
      "#########################\n",
      "### Fold 2\n",
      "### Train size 367130 Valid size 91783\n",
      "### Training with 100% fold data...\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/01 16:36:40 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 0c5f9edc7c10496681cc710c08010626. Failed operations: [MlflowException(\"Changing param values is not allowed. Param with key=\\'max_depth\\' was already logged with value=\\'4\\' for run ID=\\'0c5f9edc7c10496681cc710c08010626\\'. Attempted logging new value \\'None\\'.\")]')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric= 0.55571971576264 \n",
      "\n",
      "#########################\n",
      "### Fold 3\n",
      "### Train size 367130 Valid size 91783\n",
      "### Training with 100% fold data...\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/01 16:37:38 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 0c5f9edc7c10496681cc710c08010626. Failed operations: [MlflowException(\"Changing param values is not allowed. Param with key=\\'max_depth\\' was already logged with value=\\'4\\' for run ID=\\'0c5f9edc7c10496681cc710c08010626\\'. Attempted logging new value \\'None\\'.\")]')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric= 0.5629403701937159 \n",
      "\n",
      "#########################\n",
      "### Fold 4\n",
      "### Train size 367131 Valid size 91782\n",
      "### Training with 100% fold data...\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/01 16:38:31 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 0c5f9edc7c10496681cc710c08010626. Failed operations: [MlflowException(\"Changing param values is not allowed. Param with key=\\'max_depth\\' was already logged with value=\\'4\\' for run ID=\\'0c5f9edc7c10496681cc710c08010626\\'. Attempted logging new value \\'None\\'.\")]')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric= 0.5499840840689397 \n",
      "\n",
      "#########################\n",
      "### Fold 5\n",
      "### Train size 367131 Valid size 91782\n",
      "### Training with 100% fold data...\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/01 16:39:25 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 0c5f9edc7c10496681cc710c08010626. Failed operations: [MlflowException(\"Changing param values is not allowed. Param with key=\\'max_depth\\' was already logged with value=\\'4\\' for run ID=\\'0c5f9edc7c10496681cc710c08010626\\'. Attempted logging new value \\'None\\'.\")]')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric= 0.5526674836574395 \n",
      "\n",
      "#########################\n",
      "OVERAL CV Kaggle Metric =  0.5547401981009079\n"
     ]
    }
   ],
   "source": [
    "skf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train.target)):\n",
    "\n",
    "    if TRAIN_SUBSAMPLE < 1.0:\n",
    "        np.random.seed(42)\n",
    "        train_idx = np.random.choice(\n",
    "            train_idx, int(len(train_idx) * TRAIN_SUBSAMPLE), replace=False\n",
    "        )\n",
    "        np.random.seed(None)\n",
    "\n",
    "    print(\"#\" * 25)\n",
    "    print(\"### Fold\", fold + 1)\n",
    "    print(\"### Train size\", len(train_idx), \"Valid size\", len(valid_idx))\n",
    "    print(f\"### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...\")\n",
    "    print(\"#\" * 25)\n",
    "\n",
    "    X_train = train.loc[train_idx, FEATURES]\n",
    "    y_train = train.loc[train_idx, \"target\"]\n",
    "    X_valid = train.loc[valid_idx, FEATURES]\n",
    "    y_valid = train.loc[valid_idx, \"target\"]\n",
    "\n",
    "    model = RandomForestClassifier(n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # model.save_model(f\"../models/RegLog_{VERSION}_fold{fold}.xgb\")\n",
    "    mlflow.sklearn.log_model(model, \"RegLog\")\n",
    "\n",
    "    # dd = model.get_score(importance_type=\"weight\")\n",
    "    # df = pd.DataFrame({\"feature\": dd.keys(), f\"importance_{fold}\": dd.values()})\n",
    "    # importances.append(df)\n",
    "\n",
    "    oof_preds = model.predict(X_valid)\n",
    "    acc = amex_metric(y_valid.values, oof_preds)\n",
    "    mlflow.log_metric(\"Kaggle Metric for RegLog\", acc)\n",
    "\n",
    "    print(\"Kaggle Metric=\", acc, \"\\n\")\n",
    "\n",
    "    df = train.loc[valid_idx, [\"customer_ID\", \"target\"]].copy()\n",
    "    df[\"oof_pred\"] = oof_preds\n",
    "    oof.append(df)\n",
    "\n",
    "    del df\n",
    "    del X_valid, model\n",
    "    gc.collect()\n",
    "print(\"#\" * 25)\n",
    "oof = pd.concat(oof, axis=0, ignore_index=True).set_index(\"customer_ID\")\n",
    "acc = amex_metric(oof.target.values, oof.oof_pred.values)\n",
    "print(\"OVERAL CV Kaggle Metric = \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/01 16:39:29 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of xgboost. If you encounter errors during autologging, try upgrading / downgrading xgboost to a supported version, or try upgrading MLflow.\n",
      "2022/11/01 16:39:29 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
      "2022/11/01 16:39:29 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
      "2022/11/01 16:39:29 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    }
   ],
   "source": [
    "# Setting MLFlow\n",
    "experiment_name = \"RegLog - WoE Balanced + IV Balanced\"\n",
    "try:\n",
    "    exp_id = mlflow.create_experiment(name=experiment_name)\n",
    "except Exception as e:\n",
    "    exp_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "mlflow.autolog()\n",
    "importances = []\n",
    "oof = []\n",
    "TRAIN_SUBSAMPLE = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "### Train size 367130 Valid size 91783\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "Kaggle Metric= 0.5615669116900607 \n",
      "\n",
      "#########################\n",
      "### Fold 2\n",
      "### Train size 367130 Valid size 91783\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "Kaggle Metric= 0.5663568476478444 \n",
      "\n",
      "#########################\n",
      "### Fold 3\n",
      "### Train size 367130 Valid size 91783\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "Kaggle Metric= 0.5638556793607863 \n",
      "\n",
      "#########################\n",
      "### Fold 4\n",
      "### Train size 367131 Valid size 91782\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "Kaggle Metric= 0.5566326166751184 \n",
      "\n",
      "#########################\n",
      "### Fold 5\n",
      "### Train size 367131 Valid size 91782\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "Kaggle Metric= 0.5604082283971887 \n",
      "\n",
      "#########################\n",
      "OVERAL CV Kaggle Metric =  0.5619966622962171\n"
     ]
    }
   ],
   "source": [
    "train.fillna(-127, inplace=True)\n",
    "skf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train.target)):\n",
    "\n",
    "    if TRAIN_SUBSAMPLE < 1.0:\n",
    "        np.random.seed(42)\n",
    "        train_idx = np.random.choice(\n",
    "            train_idx, int(len(train_idx) * TRAIN_SUBSAMPLE), replace=False\n",
    "        )\n",
    "        np.random.seed(None)\n",
    "\n",
    "    print(\"#\" * 25)\n",
    "    print(\"### Fold\", fold + 1)\n",
    "    print(\"### Train size\", len(train_idx), \"Valid size\", len(valid_idx))\n",
    "    print(f\"### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...\")\n",
    "    print(\"#\" * 25)\n",
    "\n",
    "    X_train = train.loc[train_idx, FEATURES]\n",
    "    y_train = train.loc[train_idx, \"target\"]\n",
    "    X_valid = train.loc[valid_idx, FEATURES]\n",
    "    y_valid = train.loc[valid_idx, \"target\"]\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # model.save_model(f\"../models/RegLog_{VERSION}_fold{fold}.xgb\")\n",
    "    mlflow.sklearn.log_model(model, \"RegLog\")\n",
    "\n",
    "    # dd = model.get_score(importance_type=\"weight\")\n",
    "    # df = pd.DataFrame({\"feature\": dd.keys(), f\"importance_{fold}\": dd.values()})\n",
    "    # importances.append(df)\n",
    "\n",
    "    oof_preds = model.predict(X_valid)\n",
    "    acc = amex_metric(y_valid.values, oof_preds)\n",
    "    mlflow.log_metric(\"Kaggle Metric for RegLog\", acc)\n",
    "\n",
    "    print(\"Kaggle Metric=\", acc, \"\\n\")\n",
    "\n",
    "    df = train.loc[valid_idx, [\"customer_ID\", \"target\"]].copy()\n",
    "    df[\"oof_pred\"] = oof_preds\n",
    "    oof.append(df)\n",
    "\n",
    "    del df\n",
    "    del X_valid, model\n",
    "    gc.collect()\n",
    "print(\"#\" * 25)\n",
    "oof = pd.concat(oof, axis=0, ignore_index=True).set_index(\"customer_ID\")\n",
    "acc = amex_metric(oof.target.values, oof.oof_pred.values)\n",
    "print(\"OVERAL CV Kaggle Metric = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a37df45f2b4f5de47e402d1bd750bd56fcb828d129ff4ba544aa48c664b4557b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
