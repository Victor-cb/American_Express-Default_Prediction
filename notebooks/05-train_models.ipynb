{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import matplotlib.pyplot as plt, gc, os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import mlflow.lightgbm\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import warnings \n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Woe_balanced dataframe\n",
    "train = pd.read_parquet(\"../data/train_woe_balanced_downcast.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_features = pd.read_csv(\"../data/iv_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.drop('WOE_target',axis=1, inplace=True)\n",
    "FEATURES = iv_features[\"useful\"].to_list()\n",
    "FEATURES.remove(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Competition metric\n",
    "def amex_metric(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "\n",
    "xgb_params = {\n",
    "        'max_depth': 20,\n",
    "        'learning_rate':0.05,\n",
    "        'max_delta_step':3,\n",
    "        'subsample':0.6,\n",
    "        'sampling_method':'gradient_based',\n",
    "        'lambda':0.8,\n",
    "        'alpha':0.8,\n",
    "        'tree_method':'gpu_hist',\n",
    "        'scale_pos_weight':0.3317302992934773,\n",
    "        'max_bin':20,\n",
    "        'colsample_bytree':0.6, \n",
    "        'eval_metric':'logloss',\n",
    "        'objective':'binary:logistic',\n",
    "        'predictor':'auto',\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting MLFlow\n",
    "experiment_name = \"XGBoost - WoE Balanced + IV Balanced\"\n",
    "try:\n",
    "    exp_id = mlflow.create_experiment(name=experiment_name)\n",
    "except Exception as e:\n",
    "    exp_id = mlflow.get_experiment_by_name(experiment_name).experiment_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/30 16:14:09 INFO mlflow.tracking.fluent: Autologging successfully enabled for lightgbm.\n",
      "2022/09/30 16:14:10 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2022/09/30 16:14:10 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "### Train size 4425160 Valid size 1106291\n",
      "### Training with 100% fold data...\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/30 16:14:17 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '29b27ce9911746f0a005077559accf36', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current xgboost workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.66319\ttest-logloss:0.66452\n",
      "[100]\ttrain-logloss:0.21491\ttest-logloss:0.29234\n",
      "[200]\ttrain-logloss:0.16180\ttest-logloss:0.26246\n",
      "[300]\ttrain-logloss:0.12463\ttest-logloss:0.24305\n",
      "[400]\ttrain-logloss:0.09801\ttest-logloss:0.22914\n",
      "[500]\ttrain-logloss:0.07871\ttest-logloss:0.21919\n",
      "[600]\ttrain-logloss:0.06529\ttest-logloss:0.21245\n",
      "[700]\ttrain-logloss:0.05501\ttest-logloss:0.20796\n",
      "[800]\ttrain-logloss:0.04692\ttest-logloss:0.20369\n",
      "[900]\ttrain-logloss:0.04072\ttest-logloss:0.20079\n",
      "[1000]\ttrain-logloss:0.03585\ttest-logloss:0.19826\n",
      "[1100]\ttrain-logloss:0.03202\ttest-logloss:0.19654\n",
      "[1200]\ttrain-logloss:0.02887\ttest-logloss:0.19515\n",
      "[1300]\ttrain-logloss:0.02630\ttest-logloss:0.19417\n",
      "[1400]\ttrain-logloss:0.02419\ttest-logloss:0.19320\n",
      "[1500]\ttrain-logloss:0.02242\ttest-logloss:0.19240\n",
      "[1600]\ttrain-logloss:0.02088\ttest-logloss:0.19164\n",
      "[1700]\ttrain-logloss:0.01958\ttest-logloss:0.19109\n",
      "[1800]\ttrain-logloss:0.01843\ttest-logloss:0.19057\n",
      "[1900]\ttrain-logloss:0.01747\ttest-logloss:0.19021\n",
      "[2000]\ttrain-logloss:0.01658\ttest-logloss:0.18981\n",
      "[2100]\ttrain-logloss:0.01577\ttest-logloss:0.18949\n",
      "[2200]\ttrain-logloss:0.01507\ttest-logloss:0.18923\n",
      "[2300]\ttrain-logloss:0.01443\ttest-logloss:0.18891\n",
      "[2400]\ttrain-logloss:0.01385\ttest-logloss:0.18868\n",
      "[2500]\ttrain-logloss:0.01332\ttest-logloss:0.18846\n",
      "[2600]\ttrain-logloss:0.01282\ttest-logloss:0.18834\n",
      "[2700]\ttrain-logloss:0.01238\ttest-logloss:0.18816\n",
      "[2800]\ttrain-logloss:0.01198\ttest-logloss:0.18798\n",
      "[2900]\ttrain-logloss:0.01161\ttest-logloss:0.18784\n",
      "[3000]\ttrain-logloss:0.01124\ttest-logloss:0.18774\n",
      "[3100]\ttrain-logloss:0.01091\ttest-logloss:0.18761\n",
      "[3200]\ttrain-logloss:0.01061\ttest-logloss:0.18751\n",
      "[3300]\ttrain-logloss:0.01032\ttest-logloss:0.18741\n",
      "[3400]\ttrain-logloss:0.01007\ttest-logloss:0.18732\n",
      "[3500]\ttrain-logloss:0.00983\ttest-logloss:0.18729\n",
      "[3600]\ttrain-logloss:0.00959\ttest-logloss:0.18726\n",
      "[3700]\ttrain-logloss:0.00937\ttest-logloss:0.18720\n",
      "[3800]\ttrain-logloss:0.00915\ttest-logloss:0.18717\n",
      "[3900]\ttrain-logloss:0.00895\ttest-logloss:0.18707\n",
      "[4000]\ttrain-logloss:0.00877\ttest-logloss:0.18706\n",
      "[4100]\ttrain-logloss:0.00860\ttest-logloss:0.18701\n",
      "[4200]\ttrain-logloss:0.00843\ttest-logloss:0.18698\n",
      "[4300]\ttrain-logloss:0.00827\ttest-logloss:0.18698\n",
      "[4400]\ttrain-logloss:0.00812\ttest-logloss:0.18693\n",
      "[4500]\ttrain-logloss:0.00798\ttest-logloss:0.18693\n",
      "[4549]\ttrain-logloss:0.00792\ttest-logloss:0.18692\n",
      "Kaggle Metric= 0.8647060141824101 \n",
      "\n",
      "#########################\n",
      "### Fold 2\n",
      "### Train size 4425161 Valid size 1106290\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "[0]\ttrain-logloss:0.66324\ttest-logloss:0.66453\n",
      "[100]\ttrain-logloss:0.21516\ttest-logloss:0.29264\n",
      "[200]\ttrain-logloss:0.16344\ttest-logloss:0.26372\n",
      "[300]\ttrain-logloss:0.12464\ttest-logloss:0.24366\n",
      "[400]\ttrain-logloss:0.09815\ttest-logloss:0.22964\n",
      "[500]\ttrain-logloss:0.07878\ttest-logloss:0.21954\n",
      "[600]\ttrain-logloss:0.06492\ttest-logloss:0.21282\n",
      "[700]\ttrain-logloss:0.05483\ttest-logloss:0.20804\n",
      "[800]\ttrain-logloss:0.04672\ttest-logloss:0.20403\n",
      "[900]\ttrain-logloss:0.04059\ttest-logloss:0.20138\n",
      "[1000]\ttrain-logloss:0.03601\ttest-logloss:0.19894\n",
      "[1100]\ttrain-logloss:0.03215\ttest-logloss:0.19722\n",
      "[1200]\ttrain-logloss:0.02903\ttest-logloss:0.19582\n",
      "[1300]\ttrain-logloss:0.02653\ttest-logloss:0.19479\n",
      "[1400]\ttrain-logloss:0.02444\ttest-logloss:0.19384\n",
      "[1500]\ttrain-logloss:0.02267\ttest-logloss:0.19306\n",
      "[1600]\ttrain-logloss:0.02114\ttest-logloss:0.19230\n",
      "[1700]\ttrain-logloss:0.01982\ttest-logloss:0.19185\n",
      "[1800]\ttrain-logloss:0.01863\ttest-logloss:0.19131\n",
      "[1900]\ttrain-logloss:0.01764\ttest-logloss:0.19086\n",
      "[2000]\ttrain-logloss:0.01671\ttest-logloss:0.19049\n",
      "[2100]\ttrain-logloss:0.01593\ttest-logloss:0.19011\n",
      "[2200]\ttrain-logloss:0.01520\ttest-logloss:0.18979\n",
      "[2300]\ttrain-logloss:0.01454\ttest-logloss:0.18956\n",
      "[2400]\ttrain-logloss:0.01395\ttest-logloss:0.18936\n",
      "[2500]\ttrain-logloss:0.01343\ttest-logloss:0.18912\n",
      "[2600]\ttrain-logloss:0.01291\ttest-logloss:0.18902\n",
      "[2700]\ttrain-logloss:0.01246\ttest-logloss:0.18877\n",
      "[2800]\ttrain-logloss:0.01205\ttest-logloss:0.18855\n",
      "[2900]\ttrain-logloss:0.01165\ttest-logloss:0.18842\n",
      "[3000]\ttrain-logloss:0.01129\ttest-logloss:0.18832\n",
      "[3100]\ttrain-logloss:0.01096\ttest-logloss:0.18823\n",
      "[3200]\ttrain-logloss:0.01065\ttest-logloss:0.18817\n",
      "[3300]\ttrain-logloss:0.01036\ttest-logloss:0.18808\n",
      "[3400]\ttrain-logloss:0.01010\ttest-logloss:0.18797\n",
      "[3500]\ttrain-logloss:0.00985\ttest-logloss:0.18794\n",
      "[3600]\ttrain-logloss:0.00961\ttest-logloss:0.18781\n",
      "[3700]\ttrain-logloss:0.00940\ttest-logloss:0.18778\n",
      "[3800]\ttrain-logloss:0.00919\ttest-logloss:0.18770\n",
      "[3900]\ttrain-logloss:0.00899\ttest-logloss:0.18761\n",
      "[4000]\ttrain-logloss:0.00879\ttest-logloss:0.18758\n",
      "[4100]\ttrain-logloss:0.00862\ttest-logloss:0.18755\n",
      "[4200]\ttrain-logloss:0.00845\ttest-logloss:0.18753\n",
      "[4248]\ttrain-logloss:0.00836\ttest-logloss:0.18754\n",
      "Kaggle Metric= 0.8641246217320214 \n",
      "\n",
      "#########################\n",
      "### Fold 3\n",
      "### Train size 4425161 Valid size 1106290\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "[0]\ttrain-logloss:0.66312\ttest-logloss:0.66454\n",
      "[100]\ttrain-logloss:0.21512\ttest-logloss:0.29369\n",
      "[200]\ttrain-logloss:0.16253\ttest-logloss:0.26428\n",
      "[300]\ttrain-logloss:0.12603\ttest-logloss:0.24503\n",
      "[400]\ttrain-logloss:0.09827\ttest-logloss:0.23066\n",
      "[500]\ttrain-logloss:0.07915\ttest-logloss:0.22090\n",
      "[600]\ttrain-logloss:0.06557\ttest-logloss:0.21371\n",
      "[700]\ttrain-logloss:0.05542\ttest-logloss:0.20889\n",
      "[800]\ttrain-logloss:0.04725\ttest-logloss:0.20477\n",
      "[900]\ttrain-logloss:0.04095\ttest-logloss:0.20199\n",
      "[1000]\ttrain-logloss:0.03620\ttest-logloss:0.19956\n",
      "[1100]\ttrain-logloss:0.03239\ttest-logloss:0.19795\n",
      "[1200]\ttrain-logloss:0.02915\ttest-logloss:0.19657\n",
      "[1300]\ttrain-logloss:0.02657\ttest-logloss:0.19539\n",
      "[1400]\ttrain-logloss:0.02438\ttest-logloss:0.19444\n",
      "[1500]\ttrain-logloss:0.02261\ttest-logloss:0.19361\n",
      "[1600]\ttrain-logloss:0.02109\ttest-logloss:0.19283\n",
      "[1700]\ttrain-logloss:0.01977\ttest-logloss:0.19228\n",
      "[1800]\ttrain-logloss:0.01859\ttest-logloss:0.19168\n",
      "[1900]\ttrain-logloss:0.01757\ttest-logloss:0.19130\n",
      "[2000]\ttrain-logloss:0.01669\ttest-logloss:0.19098\n",
      "[2100]\ttrain-logloss:0.01589\ttest-logloss:0.19064\n",
      "[2200]\ttrain-logloss:0.01517\ttest-logloss:0.19035\n",
      "[2300]\ttrain-logloss:0.01451\ttest-logloss:0.19006\n",
      "[2400]\ttrain-logloss:0.01393\ttest-logloss:0.18980\n",
      "[2500]\ttrain-logloss:0.01337\ttest-logloss:0.18955\n",
      "[2600]\ttrain-logloss:0.01286\ttest-logloss:0.18937\n",
      "[2700]\ttrain-logloss:0.01242\ttest-logloss:0.18917\n",
      "[2800]\ttrain-logloss:0.01200\ttest-logloss:0.18898\n",
      "[2900]\ttrain-logloss:0.01162\ttest-logloss:0.18883\n",
      "[3000]\ttrain-logloss:0.01126\ttest-logloss:0.18871\n",
      "[3100]\ttrain-logloss:0.01093\ttest-logloss:0.18858\n",
      "[3200]\ttrain-logloss:0.01063\ttest-logloss:0.18849\n",
      "[3300]\ttrain-logloss:0.01035\ttest-logloss:0.18839\n",
      "[3400]\ttrain-logloss:0.01009\ttest-logloss:0.18830\n",
      "[3500]\ttrain-logloss:0.00985\ttest-logloss:0.18821\n",
      "[3600]\ttrain-logloss:0.00961\ttest-logloss:0.18814\n",
      "[3700]\ttrain-logloss:0.00939\ttest-logloss:0.18807\n",
      "[3800]\ttrain-logloss:0.00918\ttest-logloss:0.18797\n",
      "[3900]\ttrain-logloss:0.00898\ttest-logloss:0.18788\n",
      "[4000]\ttrain-logloss:0.00879\ttest-logloss:0.18786\n",
      "[4100]\ttrain-logloss:0.00862\ttest-logloss:0.18783\n",
      "[4200]\ttrain-logloss:0.00845\ttest-logloss:0.18778\n",
      "[4300]\ttrain-logloss:0.00829\ttest-logloss:0.18778\n",
      "[4400]\ttrain-logloss:0.00813\ttest-logloss:0.18774\n",
      "[4500]\ttrain-logloss:0.00799\ttest-logloss:0.18771\n",
      "[4564]\ttrain-logloss:0.00790\ttest-logloss:0.18772\n",
      "Kaggle Metric= 0.8645830710920044 \n",
      "\n",
      "#########################\n",
      "### Fold 4\n",
      "### Train size 4425161 Valid size 1106290\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "[0]\ttrain-logloss:0.66317\ttest-logloss:0.66455\n",
      "[100]\ttrain-logloss:0.21498\ttest-logloss:0.29344\n",
      "[200]\ttrain-logloss:0.16280\ttest-logloss:0.26398\n",
      "[300]\ttrain-logloss:0.12261\ttest-logloss:0.24368\n",
      "[400]\ttrain-logloss:0.09618\ttest-logloss:0.22973\n",
      "[500]\ttrain-logloss:0.07812\ttest-logloss:0.22025\n",
      "[600]\ttrain-logloss:0.06475\ttest-logloss:0.21365\n",
      "[700]\ttrain-logloss:0.05436\ttest-logloss:0.20869\n",
      "[800]\ttrain-logloss:0.04656\ttest-logloss:0.20466\n",
      "[900]\ttrain-logloss:0.04048\ttest-logloss:0.20190\n",
      "[1000]\ttrain-logloss:0.03570\ttest-logloss:0.19963\n",
      "[1100]\ttrain-logloss:0.03180\ttest-logloss:0.19791\n",
      "[1200]\ttrain-logloss:0.02870\ttest-logloss:0.19647\n",
      "[1300]\ttrain-logloss:0.02623\ttest-logloss:0.19538\n",
      "[1400]\ttrain-logloss:0.02414\ttest-logloss:0.19446\n",
      "[1500]\ttrain-logloss:0.02244\ttest-logloss:0.19360\n",
      "[1600]\ttrain-logloss:0.02096\ttest-logloss:0.19293\n",
      "[1700]\ttrain-logloss:0.01971\ttest-logloss:0.19243\n",
      "[1800]\ttrain-logloss:0.01856\ttest-logloss:0.19180\n",
      "[1900]\ttrain-logloss:0.01754\ttest-logloss:0.19139\n",
      "[2000]\ttrain-logloss:0.01666\ttest-logloss:0.19105\n",
      "[2100]\ttrain-logloss:0.01584\ttest-logloss:0.19061\n",
      "[2200]\ttrain-logloss:0.01512\ttest-logloss:0.19038\n",
      "[2300]\ttrain-logloss:0.01449\ttest-logloss:0.19014\n",
      "[2400]\ttrain-logloss:0.01390\ttest-logloss:0.18992\n",
      "[2500]\ttrain-logloss:0.01336\ttest-logloss:0.18978\n",
      "[2600]\ttrain-logloss:0.01286\ttest-logloss:0.18963\n",
      "[2700]\ttrain-logloss:0.01242\ttest-logloss:0.18942\n",
      "[2800]\ttrain-logloss:0.01201\ttest-logloss:0.18927\n",
      "[2900]\ttrain-logloss:0.01164\ttest-logloss:0.18912\n",
      "[3000]\ttrain-logloss:0.01127\ttest-logloss:0.18899\n",
      "[3100]\ttrain-logloss:0.01095\ttest-logloss:0.18892\n",
      "[3200]\ttrain-logloss:0.01064\ttest-logloss:0.18883\n",
      "[3300]\ttrain-logloss:0.01036\ttest-logloss:0.18874\n",
      "[3400]\ttrain-logloss:0.01009\ttest-logloss:0.18864\n",
      "[3500]\ttrain-logloss:0.00984\ttest-logloss:0.18855\n",
      "[3600]\ttrain-logloss:0.00961\ttest-logloss:0.18846\n",
      "[3700]\ttrain-logloss:0.00939\ttest-logloss:0.18841\n",
      "[3800]\ttrain-logloss:0.00918\ttest-logloss:0.18837\n",
      "[3900]\ttrain-logloss:0.00898\ttest-logloss:0.18826\n",
      "[4000]\ttrain-logloss:0.00879\ttest-logloss:0.18822\n",
      "[4100]\ttrain-logloss:0.00862\ttest-logloss:0.18815\n",
      "[4200]\ttrain-logloss:0.00845\ttest-logloss:0.18814\n",
      "[4230]\ttrain-logloss:0.00840\ttest-logloss:0.18815\n",
      "Kaggle Metric= 0.8632171544032006 \n",
      "\n",
      "#########################\n",
      "### Fold 5\n",
      "### Train size 4425161 Valid size 1106290\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "[0]\ttrain-logloss:0.66321\ttest-logloss:0.66457\n",
      "[100]\ttrain-logloss:0.21520\ttest-logloss:0.29384\n",
      "[200]\ttrain-logloss:0.16303\ttest-logloss:0.26460\n",
      "[300]\ttrain-logloss:0.12445\ttest-logloss:0.24411\n",
      "[400]\ttrain-logloss:0.09752\ttest-logloss:0.23003\n",
      "[500]\ttrain-logloss:0.07972\ttest-logloss:0.22069\n",
      "[600]\ttrain-logloss:0.06576\ttest-logloss:0.21365\n",
      "[700]\ttrain-logloss:0.05566\ttest-logloss:0.20884\n",
      "[800]\ttrain-logloss:0.04712\ttest-logloss:0.20475\n",
      "[900]\ttrain-logloss:0.04100\ttest-logloss:0.20202\n",
      "[1000]\ttrain-logloss:0.03616\ttest-logloss:0.19976\n",
      "[1100]\ttrain-logloss:0.03240\ttest-logloss:0.19798\n",
      "[1200]\ttrain-logloss:0.02923\ttest-logloss:0.19647\n",
      "[1300]\ttrain-logloss:0.02652\ttest-logloss:0.19540\n",
      "[1400]\ttrain-logloss:0.02437\ttest-logloss:0.19439\n",
      "[1500]\ttrain-logloss:0.02257\ttest-logloss:0.19370\n",
      "[1600]\ttrain-logloss:0.02101\ttest-logloss:0.19290\n",
      "[1700]\ttrain-logloss:0.01969\ttest-logloss:0.19240\n",
      "[1800]\ttrain-logloss:0.01857\ttest-logloss:0.19181\n",
      "[1900]\ttrain-logloss:0.01757\ttest-logloss:0.19139\n",
      "[2000]\ttrain-logloss:0.01669\ttest-logloss:0.19104\n",
      "[2100]\ttrain-logloss:0.01588\ttest-logloss:0.19068\n",
      "[2200]\ttrain-logloss:0.01514\ttest-logloss:0.19031\n",
      "[2300]\ttrain-logloss:0.01449\ttest-logloss:0.19004\n",
      "[2400]\ttrain-logloss:0.01393\ttest-logloss:0.18980\n",
      "[2500]\ttrain-logloss:0.01339\ttest-logloss:0.18955\n",
      "[2600]\ttrain-logloss:0.01288\ttest-logloss:0.18944\n",
      "[2700]\ttrain-logloss:0.01243\ttest-logloss:0.18924\n",
      "[2800]\ttrain-logloss:0.01200\ttest-logloss:0.18907\n",
      "[2900]\ttrain-logloss:0.01162\ttest-logloss:0.18894\n",
      "[3000]\ttrain-logloss:0.01126\ttest-logloss:0.18885\n",
      "[3100]\ttrain-logloss:0.01093\ttest-logloss:0.18873\n",
      "[3200]\ttrain-logloss:0.01063\ttest-logloss:0.18865\n",
      "[3300]\ttrain-logloss:0.01034\ttest-logloss:0.18856\n",
      "[3400]\ttrain-logloss:0.01008\ttest-logloss:0.18849\n",
      "[3500]\ttrain-logloss:0.00983\ttest-logloss:0.18850\n",
      "[3600]\ttrain-logloss:0.00959\ttest-logloss:0.18845\n",
      "[3700]\ttrain-logloss:0.00937\ttest-logloss:0.18840\n",
      "[3800]\ttrain-logloss:0.00915\ttest-logloss:0.18836\n",
      "[3900]\ttrain-logloss:0.00896\ttest-logloss:0.18829\n",
      "[4000]\ttrain-logloss:0.00877\ttest-logloss:0.18823\n",
      "[4100]\ttrain-logloss:0.00860\ttest-logloss:0.18818\n",
      "[4200]\ttrain-logloss:0.00843\ttest-logloss:0.18816\n",
      "[4240]\ttrain-logloss:0.00836\ttest-logloss:0.18816\n",
      "Kaggle Metric= 0.8640512273992687 \n",
      "\n",
      "#########################\n",
      "OVERAL CV Kaggle Metric =  0.8641207831184039\n"
     ]
    }
   ],
   "source": [
    "mlflow.autolog()\n",
    "importances = []\n",
    "oof = []\n",
    "TRAIN_SUBSAMPLE = 1.0\n",
    "\n",
    "skf = KFold(n_splits = 5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train.target)):\n",
    "\n",
    "    if TRAIN_SUBSAMPLE<1.0:\n",
    "        np.random.seed(42)\n",
    "        train_idx = np.random.choice(train_idx, \n",
    "                       int(len(train_idx)*TRAIN_SUBSAMPLE), replace=False)\n",
    "        np.random.seed(None)\n",
    "        \n",
    "    print('#'*25)\n",
    "    print('### Fold',fold+1)\n",
    "    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n",
    "    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n",
    "    print('#'*25)\n",
    "\n",
    "    X_train = train.loc[train_idx, FEATURES]\n",
    "    y_train = train.loc[train_idx, 'target']\n",
    "    X_valid = train.loc[valid_idx, FEATURES]\n",
    "    y_valid = train.loc[valid_idx, 'target']\n",
    "\n",
    "    dtrain=xgb.DMatrix(X_train, \n",
    "                        y_train)\n",
    "    del X_train, y_train\n",
    "    gc.collect()\n",
    "    d_valid = xgb.DMatrix(X_valid, \n",
    "                        y_valid)\n",
    "    del X_valid\n",
    "    gc.collect()\n",
    "    model = xgb.train(\n",
    "                    xgb_params,\n",
    "                    dtrain=dtrain,\n",
    "                    evals=[(dtrain, 'train'), (d_valid, 'test')],\n",
    "                    num_boost_round= 9999,\n",
    "                    early_stopping_rounds = 100,\n",
    "                    verbose_eval= 100\n",
    "                                                \n",
    "                    )\n",
    "\n",
    "    model.save_model(f'../models/XGB_V_fold{fold}.xgb')\n",
    "    mlflow.xgboost.log_model(model, \"XGBClassifier\")\n",
    "\n",
    "    dd = model.get_score(importance_type='weight')\n",
    "    df= pd.DataFrame({'feature':dd.keys(), f'importance_{fold}':dd.values()})\n",
    "    importances.append(df)\n",
    "    \n",
    "    oof_preds = model.predict(d_valid)\n",
    "    acc = amex_metric(y_valid.values, oof_preds)\n",
    "    mlflow.log_metric(\"Kaggle Metric for XGBClassifier\", acc)\n",
    "\n",
    "    print(\"Kaggle Metric=\", acc,'\\n')\n",
    "\n",
    "    df = train.loc[valid_idx, ['customer_ID', 'target']].copy()\n",
    "    df['oof_pred']= oof_preds\n",
    "    oof.append(df)\n",
    "\n",
    "    del   dd, df\n",
    "    del  d_valid, model\n",
    "    gc.collect()\n",
    "print('#'*25)\n",
    "oof = pd.concat(oof, axis=0, ignore_index=True).set_index('customer_ID')\n",
    "acc= amex_metric(oof.target.values, oof.oof_pred.values)\n",
    "print('OVERAL CV Kaggle Metric = ', acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fddb47bc9764f917e582b0801b6a9ae07a3476d8133832258babead972bf3eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
