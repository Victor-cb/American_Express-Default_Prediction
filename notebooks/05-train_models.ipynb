{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import matplotlib.pyplot as plt, gc, os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import mlflow.lightgbm\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import warnings \n",
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Woe_balanced dataframe\n",
    "train = pd.read_parquet(\"../data/final/train_woe.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_features = pd.read_csv(\"../reports/iv_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.drop('WOE_target',axis=1, inplace=True)\n",
    "FEATURES = iv_features[\"useful\"].to_list()\n",
    "FEATURES.remove(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Competition metric\n",
    "def amex_metric(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "\n",
    "xgb_params = {\n",
    "        'max_depth': 20,\n",
    "        'learning_rate':0.05,\n",
    "        'max_delta_step':3,\n",
    "        'subsample':0.6,\n",
    "        'sampling_method':'gradient_based',\n",
    "        'lambda':0.8,\n",
    "        'alpha':0.8,\n",
    "        'tree_method':'gpu_hist',\n",
    "        'scale_pos_weight':0.3317302992934773,\n",
    "        'max_bin':20,\n",
    "        'colsample_bytree':0.6, \n",
    "        'eval_metric':'logloss',\n",
    "        'objective':'binary:logistic',\n",
    "        'predictor':'auto',\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting MLFlow\n",
    "experiment_name = \"XGBoost - WoE Balanced + IV Balanced\"\n",
    "try:\n",
    "    exp_id = mlflow.create_experiment(name=experiment_name)\n",
    "except Exception as e:\n",
    "    exp_id = mlflow.get_experiment_by_name(experiment_name).experiment_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/05 21:19:40 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
      "2022/10/05 21:19:40 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "### Train size 4425160 Valid size 1106291\n",
      "### Training with 100% fold data...\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/05 21:19:47 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b918e58a2a1e4c6db6ab63993224fc03', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current xgboost workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.66319\ttest-logloss:0.66452\n",
      "[100]\ttrain-logloss:0.21480\ttest-logloss:0.29217\n",
      "[200]\ttrain-logloss:0.16169\ttest-logloss:0.26243\n",
      "[300]\ttrain-logloss:0.12373\ttest-logloss:0.24317\n",
      "[400]\ttrain-logloss:0.09736\ttest-logloss:0.22923\n",
      "[500]\ttrain-logloss:0.07859\ttest-logloss:0.21946\n",
      "[600]\ttrain-logloss:0.06472\ttest-logloss:0.21259\n",
      "[700]\ttrain-logloss:0.05477\ttest-logloss:0.20802\n",
      "[800]\ttrain-logloss:0.04659\ttest-logloss:0.20413\n",
      "[900]\ttrain-logloss:0.04056\ttest-logloss:0.20135\n",
      "[1000]\ttrain-logloss:0.03590\ttest-logloss:0.19898\n",
      "[1100]\ttrain-logloss:0.03202\ttest-logloss:0.19712\n",
      "[1200]\ttrain-logloss:0.02899\ttest-logloss:0.19579\n",
      "[1300]\ttrain-logloss:0.02641\ttest-logloss:0.19470\n",
      "[1400]\ttrain-logloss:0.02430\ttest-logloss:0.19373\n",
      "[1500]\ttrain-logloss:0.02257\ttest-logloss:0.19283\n",
      "[1600]\ttrain-logloss:0.02102\ttest-logloss:0.19206\n",
      "[1700]\ttrain-logloss:0.01975\ttest-logloss:0.19153\n",
      "[1800]\ttrain-logloss:0.01859\ttest-logloss:0.19091\n",
      "[1900]\ttrain-logloss:0.01759\ttest-logloss:0.19051\n",
      "[2000]\ttrain-logloss:0.01666\ttest-logloss:0.19021\n",
      "[2100]\ttrain-logloss:0.01583\ttest-logloss:0.18983\n",
      "[2200]\ttrain-logloss:0.01512\ttest-logloss:0.18953\n",
      "[2300]\ttrain-logloss:0.01447\ttest-logloss:0.18923\n",
      "[2400]\ttrain-logloss:0.01388\ttest-logloss:0.18900\n",
      "[2500]\ttrain-logloss:0.01335\ttest-logloss:0.18878\n",
      "[2600]\ttrain-logloss:0.01287\ttest-logloss:0.18863\n",
      "[2700]\ttrain-logloss:0.01241\ttest-logloss:0.18840\n",
      "[2800]\ttrain-logloss:0.01199\ttest-logloss:0.18818\n",
      "[2900]\ttrain-logloss:0.01161\ttest-logloss:0.18805\n",
      "[3000]\ttrain-logloss:0.01126\ttest-logloss:0.18799\n",
      "[3100]\ttrain-logloss:0.01093\ttest-logloss:0.18782\n",
      "[3200]\ttrain-logloss:0.01062\ttest-logloss:0.18774\n",
      "[3300]\ttrain-logloss:0.01034\ttest-logloss:0.18764\n",
      "[3400]\ttrain-logloss:0.01008\ttest-logloss:0.18751\n",
      "[3500]\ttrain-logloss:0.00983\ttest-logloss:0.18748\n",
      "[3600]\ttrain-logloss:0.00960\ttest-logloss:0.18740\n",
      "[3700]\ttrain-logloss:0.00937\ttest-logloss:0.18730\n",
      "[3800]\ttrain-logloss:0.00916\ttest-logloss:0.18722\n",
      "[3900]\ttrain-logloss:0.00896\ttest-logloss:0.18712\n",
      "[4000]\ttrain-logloss:0.00877\ttest-logloss:0.18709\n",
      "[4100]\ttrain-logloss:0.00860\ttest-logloss:0.18706\n",
      "[4200]\ttrain-logloss:0.00843\ttest-logloss:0.18701\n",
      "[4270]\ttrain-logloss:0.00832\ttest-logloss:0.18701\n",
      "Kaggle Metric= 0.8642061635576319 \n",
      "\n",
      "#########################\n",
      "### Fold 2\n",
      "### Train size 4425161 Valid size 1106290\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "[0]\ttrain-logloss:0.66324\ttest-logloss:0.66453\n",
      "[100]\ttrain-logloss:0.21550\ttest-logloss:0.29275\n",
      "[200]\ttrain-logloss:0.16405\ttest-logloss:0.26409\n",
      "[300]\ttrain-logloss:0.12497\ttest-logloss:0.24347\n",
      "[400]\ttrain-logloss:0.09837\ttest-logloss:0.23001\n",
      "[500]\ttrain-logloss:0.07878\ttest-logloss:0.21996\n",
      "[600]\ttrain-logloss:0.06514\ttest-logloss:0.21351\n",
      "[700]\ttrain-logloss:0.05468\ttest-logloss:0.20864\n",
      "[800]\ttrain-logloss:0.04663\ttest-logloss:0.20453\n",
      "[900]\ttrain-logloss:0.04060\ttest-logloss:0.20175\n",
      "[1000]\ttrain-logloss:0.03588\ttest-logloss:0.19941\n",
      "[1100]\ttrain-logloss:0.03212\ttest-logloss:0.19773\n",
      "[1200]\ttrain-logloss:0.02908\ttest-logloss:0.19643\n",
      "[1300]\ttrain-logloss:0.02652\ttest-logloss:0.19534\n",
      "[1400]\ttrain-logloss:0.02444\ttest-logloss:0.19432\n",
      "[1500]\ttrain-logloss:0.02263\ttest-logloss:0.19340\n",
      "[1600]\ttrain-logloss:0.02107\ttest-logloss:0.19264\n",
      "[1700]\ttrain-logloss:0.01982\ttest-logloss:0.19218\n",
      "[1800]\ttrain-logloss:0.01864\ttest-logloss:0.19160\n",
      "[1900]\ttrain-logloss:0.01768\ttest-logloss:0.19123\n",
      "[2000]\ttrain-logloss:0.01676\ttest-logloss:0.19080\n",
      "[2100]\ttrain-logloss:0.01596\ttest-logloss:0.19039\n",
      "[2200]\ttrain-logloss:0.01524\ttest-logloss:0.19009\n",
      "[2300]\ttrain-logloss:0.01457\ttest-logloss:0.18980\n",
      "[2400]\ttrain-logloss:0.01397\ttest-logloss:0.18958\n",
      "[2500]\ttrain-logloss:0.01344\ttest-logloss:0.18937\n",
      "[2600]\ttrain-logloss:0.01294\ttest-logloss:0.18923\n",
      "[2700]\ttrain-logloss:0.01249\ttest-logloss:0.18903\n",
      "[2800]\ttrain-logloss:0.01208\ttest-logloss:0.18884\n",
      "[2900]\ttrain-logloss:0.01170\ttest-logloss:0.18867\n",
      "[3000]\ttrain-logloss:0.01134\ttest-logloss:0.18855\n",
      "[3100]\ttrain-logloss:0.01102\ttest-logloss:0.18843\n",
      "[3200]\ttrain-logloss:0.01071\ttest-logloss:0.18837\n",
      "[3300]\ttrain-logloss:0.01042\ttest-logloss:0.18826\n",
      "[3400]\ttrain-logloss:0.01016\ttest-logloss:0.18817\n",
      "[3500]\ttrain-logloss:0.00991\ttest-logloss:0.18814\n",
      "[3600]\ttrain-logloss:0.00967\ttest-logloss:0.18808\n",
      "[3700]\ttrain-logloss:0.00944\ttest-logloss:0.18807\n",
      "[3800]\ttrain-logloss:0.00922\ttest-logloss:0.18802\n",
      "[3900]\ttrain-logloss:0.00902\ttest-logloss:0.18796\n",
      "[4000]\ttrain-logloss:0.00884\ttest-logloss:0.18790\n",
      "[4100]\ttrain-logloss:0.00866\ttest-logloss:0.18785\n",
      "[4200]\ttrain-logloss:0.00849\ttest-logloss:0.18784\n",
      "[4237]\ttrain-logloss:0.00843\ttest-logloss:0.18784\n",
      "Kaggle Metric= 0.863263274570713 \n",
      "\n",
      "#########################\n",
      "### Fold 3\n",
      "### Train size 4425161 Valid size 1106290\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "[0]\ttrain-logloss:0.66312\ttest-logloss:0.66454\n",
      "[100]\ttrain-logloss:0.21483\ttest-logloss:0.29349\n",
      "[200]\ttrain-logloss:0.16269\ttest-logloss:0.26421\n",
      "[300]\ttrain-logloss:0.12587\ttest-logloss:0.24510\n",
      "[400]\ttrain-logloss:0.09774\ttest-logloss:0.23063\n",
      "[500]\ttrain-logloss:0.07857\ttest-logloss:0.22049\n",
      "[600]\ttrain-logloss:0.06443\ttest-logloss:0.21351\n",
      "[700]\ttrain-logloss:0.05431\ttest-logloss:0.20874\n",
      "[800]\ttrain-logloss:0.04649\ttest-logloss:0.20477\n",
      "[900]\ttrain-logloss:0.04053\ttest-logloss:0.20211\n",
      "[1000]\ttrain-logloss:0.03586\ttest-logloss:0.19973\n",
      "[1100]\ttrain-logloss:0.03200\ttest-logloss:0.19791\n",
      "[1200]\ttrain-logloss:0.02903\ttest-logloss:0.19651\n",
      "[1300]\ttrain-logloss:0.02651\ttest-logloss:0.19543\n",
      "[1400]\ttrain-logloss:0.02434\ttest-logloss:0.19443\n",
      "[1500]\ttrain-logloss:0.02259\ttest-logloss:0.19364\n",
      "[1600]\ttrain-logloss:0.02112\ttest-logloss:0.19288\n",
      "[1700]\ttrain-logloss:0.01976\ttest-logloss:0.19222\n",
      "[1800]\ttrain-logloss:0.01859\ttest-logloss:0.19172\n",
      "[1900]\ttrain-logloss:0.01759\ttest-logloss:0.19123\n",
      "[2000]\ttrain-logloss:0.01667\ttest-logloss:0.19087\n",
      "[2100]\ttrain-logloss:0.01588\ttest-logloss:0.19054\n",
      "[2200]\ttrain-logloss:0.01519\ttest-logloss:0.19021\n",
      "[2300]\ttrain-logloss:0.01454\ttest-logloss:0.18991\n",
      "[2400]\ttrain-logloss:0.01395\ttest-logloss:0.18966\n",
      "[2500]\ttrain-logloss:0.01340\ttest-logloss:0.18935\n",
      "[2600]\ttrain-logloss:0.01289\ttest-logloss:0.18919\n",
      "[2700]\ttrain-logloss:0.01243\ttest-logloss:0.18900\n",
      "[2800]\ttrain-logloss:0.01202\ttest-logloss:0.18884\n",
      "[2900]\ttrain-logloss:0.01166\ttest-logloss:0.18866\n",
      "[3000]\ttrain-logloss:0.01130\ttest-logloss:0.18856\n",
      "[3100]\ttrain-logloss:0.01096\ttest-logloss:0.18842\n",
      "[3200]\ttrain-logloss:0.01066\ttest-logloss:0.18834\n",
      "[3300]\ttrain-logloss:0.01038\ttest-logloss:0.18822\n",
      "[3400]\ttrain-logloss:0.01012\ttest-logloss:0.18810\n",
      "[3500]\ttrain-logloss:0.00987\ttest-logloss:0.18803\n",
      "[3600]\ttrain-logloss:0.00964\ttest-logloss:0.18796\n",
      "[3700]\ttrain-logloss:0.00943\ttest-logloss:0.18791\n",
      "[3800]\ttrain-logloss:0.00922\ttest-logloss:0.18786\n",
      "[3900]\ttrain-logloss:0.00902\ttest-logloss:0.18779\n",
      "[4000]\ttrain-logloss:0.00883\ttest-logloss:0.18777\n",
      "[4100]\ttrain-logloss:0.00865\ttest-logloss:0.18772\n",
      "[4200]\ttrain-logloss:0.00848\ttest-logloss:0.18772\n",
      "[4231]\ttrain-logloss:0.00843\ttest-logloss:0.18772\n",
      "Kaggle Metric= 0.8639458404799654 \n",
      "\n",
      "#########################\n",
      "### Fold 4\n",
      "### Train size 4425161 Valid size 1106290\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "[0]\ttrain-logloss:0.66317\ttest-logloss:0.66455\n",
      "[100]\ttrain-logloss:0.21517\ttest-logloss:0.29344\n",
      "[200]\ttrain-logloss:0.16325\ttest-logloss:0.26425\n",
      "[300]\ttrain-logloss:0.12475\ttest-logloss:0.24488\n",
      "[400]\ttrain-logloss:0.09758\ttest-logloss:0.23025\n",
      "[500]\ttrain-logloss:0.07856\ttest-logloss:0.22039\n",
      "[600]\ttrain-logloss:0.06481\ttest-logloss:0.21376\n",
      "[700]\ttrain-logloss:0.05484\ttest-logloss:0.20906\n",
      "[800]\ttrain-logloss:0.04687\ttest-logloss:0.20492\n",
      "[900]\ttrain-logloss:0.04085\ttest-logloss:0.20215\n",
      "[1000]\ttrain-logloss:0.03609\ttest-logloss:0.19979\n",
      "[1100]\ttrain-logloss:0.03226\ttest-logloss:0.19813\n",
      "[1200]\ttrain-logloss:0.02910\ttest-logloss:0.19672\n",
      "[1300]\ttrain-logloss:0.02654\ttest-logloss:0.19569\n",
      "[1400]\ttrain-logloss:0.02432\ttest-logloss:0.19462\n",
      "[1500]\ttrain-logloss:0.02252\ttest-logloss:0.19379\n",
      "[1600]\ttrain-logloss:0.02099\ttest-logloss:0.19303\n",
      "[1700]\ttrain-logloss:0.01968\ttest-logloss:0.19251\n",
      "[1800]\ttrain-logloss:0.01849\ttest-logloss:0.19193\n",
      "[1900]\ttrain-logloss:0.01750\ttest-logloss:0.19154\n",
      "[2000]\ttrain-logloss:0.01663\ttest-logloss:0.19123\n",
      "[2100]\ttrain-logloss:0.01584\ttest-logloss:0.19091\n",
      "[2200]\ttrain-logloss:0.01510\ttest-logloss:0.19063\n",
      "[2300]\ttrain-logloss:0.01446\ttest-logloss:0.19042\n",
      "[2400]\ttrain-logloss:0.01388\ttest-logloss:0.19012\n",
      "[2500]\ttrain-logloss:0.01334\ttest-logloss:0.18988\n",
      "[2600]\ttrain-logloss:0.01285\ttest-logloss:0.18971\n",
      "[2700]\ttrain-logloss:0.01239\ttest-logloss:0.18952\n",
      "[2800]\ttrain-logloss:0.01199\ttest-logloss:0.18932\n",
      "[2900]\ttrain-logloss:0.01161\ttest-logloss:0.18914\n",
      "[3000]\ttrain-logloss:0.01125\ttest-logloss:0.18905\n",
      "[3100]\ttrain-logloss:0.01092\ttest-logloss:0.18897\n",
      "[3200]\ttrain-logloss:0.01060\ttest-logloss:0.18891\n",
      "[3300]\ttrain-logloss:0.01033\ttest-logloss:0.18882\n",
      "[3400]\ttrain-logloss:0.01007\ttest-logloss:0.18870\n",
      "[3500]\ttrain-logloss:0.00982\ttest-logloss:0.18862\n",
      "[3600]\ttrain-logloss:0.00959\ttest-logloss:0.18855\n",
      "[3700]\ttrain-logloss:0.00936\ttest-logloss:0.18849\n",
      "[3800]\ttrain-logloss:0.00915\ttest-logloss:0.18844\n",
      "[3900]\ttrain-logloss:0.00895\ttest-logloss:0.18835\n",
      "[4000]\ttrain-logloss:0.00876\ttest-logloss:0.18828\n",
      "[4100]\ttrain-logloss:0.00858\ttest-logloss:0.18821\n",
      "[4200]\ttrain-logloss:0.00841\ttest-logloss:0.18821\n",
      "[4300]\ttrain-logloss:0.00825\ttest-logloss:0.18814\n",
      "[4400]\ttrain-logloss:0.00810\ttest-logloss:0.18814\n",
      "[4500]\ttrain-logloss:0.00796\ttest-logloss:0.18811\n",
      "[4600]\ttrain-logloss:0.00782\ttest-logloss:0.18809\n",
      "[4700]\ttrain-logloss:0.00769\ttest-logloss:0.18807\n",
      "[4800]\ttrain-logloss:0.00756\ttest-logloss:0.18807\n",
      "[4900]\ttrain-logloss:0.00744\ttest-logloss:0.18803\n",
      "[5000]\ttrain-logloss:0.00732\ttest-logloss:0.18802\n",
      "[5100]\ttrain-logloss:0.00721\ttest-logloss:0.18800\n",
      "[5128]\ttrain-logloss:0.00718\ttest-logloss:0.18802\n",
      "Kaggle Metric= 0.8650703405387358 \n",
      "\n",
      "#########################\n",
      "### Fold 5\n",
      "### Train size 4425161 Valid size 1106290\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "[0]\ttrain-logloss:0.66321\ttest-logloss:0.66457\n",
      "[100]\ttrain-logloss:0.21540\ttest-logloss:0.29376\n",
      "[200]\ttrain-logloss:0.16233\ttest-logloss:0.26451\n",
      "[300]\ttrain-logloss:0.12509\ttest-logloss:0.24482\n",
      "[400]\ttrain-logloss:0.09704\ttest-logloss:0.23053\n",
      "[500]\ttrain-logloss:0.07832\ttest-logloss:0.22079\n",
      "[600]\ttrain-logloss:0.06472\ttest-logloss:0.21379\n",
      "[700]\ttrain-logloss:0.05472\ttest-logloss:0.20884\n",
      "[800]\ttrain-logloss:0.04663\ttest-logloss:0.20503\n",
      "[900]\ttrain-logloss:0.04070\ttest-logloss:0.20230\n",
      "[1000]\ttrain-logloss:0.03596\ttest-logloss:0.19992\n",
      "[1100]\ttrain-logloss:0.03208\ttest-logloss:0.19822\n",
      "[1200]\ttrain-logloss:0.02905\ttest-logloss:0.19680\n",
      "[1300]\ttrain-logloss:0.02652\ttest-logloss:0.19592\n",
      "[1400]\ttrain-logloss:0.02447\ttest-logloss:0.19495\n",
      "[1500]\ttrain-logloss:0.02264\ttest-logloss:0.19401\n",
      "[1600]\ttrain-logloss:0.02108\ttest-logloss:0.19323\n",
      "[1700]\ttrain-logloss:0.01975\ttest-logloss:0.19267\n",
      "[1800]\ttrain-logloss:0.01854\ttest-logloss:0.19204\n",
      "[1900]\ttrain-logloss:0.01752\ttest-logloss:0.19180\n",
      "[2000]\ttrain-logloss:0.01662\ttest-logloss:0.19143\n",
      "[2100]\ttrain-logloss:0.01580\ttest-logloss:0.19103\n",
      "[2200]\ttrain-logloss:0.01510\ttest-logloss:0.19071\n",
      "[2300]\ttrain-logloss:0.01446\ttest-logloss:0.19046\n",
      "[2400]\ttrain-logloss:0.01386\ttest-logloss:0.19019\n",
      "[2500]\ttrain-logloss:0.01332\ttest-logloss:0.18998\n",
      "[2600]\ttrain-logloss:0.01283\ttest-logloss:0.18986\n",
      "[2700]\ttrain-logloss:0.01237\ttest-logloss:0.18968\n",
      "[2800]\ttrain-logloss:0.01197\ttest-logloss:0.18948\n",
      "[2900]\ttrain-logloss:0.01159\ttest-logloss:0.18937\n",
      "[3000]\ttrain-logloss:0.01122\ttest-logloss:0.18930\n",
      "[3100]\ttrain-logloss:0.01089\ttest-logloss:0.18918\n",
      "[3200]\ttrain-logloss:0.01059\ttest-logloss:0.18910\n",
      "[3300]\ttrain-logloss:0.01031\ttest-logloss:0.18899\n",
      "[3400]\ttrain-logloss:0.01005\ttest-logloss:0.18891\n",
      "[3500]\ttrain-logloss:0.00981\ttest-logloss:0.18886\n",
      "[3600]\ttrain-logloss:0.00958\ttest-logloss:0.18878\n",
      "[3700]\ttrain-logloss:0.00936\ttest-logloss:0.18871\n",
      "[3800]\ttrain-logloss:0.00915\ttest-logloss:0.18870\n",
      "[3900]\ttrain-logloss:0.00895\ttest-logloss:0.18860\n",
      "[4000]\ttrain-logloss:0.00877\ttest-logloss:0.18854\n",
      "[4100]\ttrain-logloss:0.00860\ttest-logloss:0.18850\n",
      "[4200]\ttrain-logloss:0.00844\ttest-logloss:0.18847\n",
      "[4300]\ttrain-logloss:0.00828\ttest-logloss:0.18843\n",
      "[4400]\ttrain-logloss:0.00812\ttest-logloss:0.18841\n",
      "[4500]\ttrain-logloss:0.00797\ttest-logloss:0.18838\n",
      "[4600]\ttrain-logloss:0.00783\ttest-logloss:0.18837\n",
      "[4654]\ttrain-logloss:0.00776\ttest-logloss:0.18836\n",
      "Kaggle Metric= 0.8642759596356209 \n",
      "\n",
      "#########################\n",
      "OVERAL CV Kaggle Metric =  0.8641515714199203\n"
     ]
    }
   ],
   "source": [
    "mlflow.autolog()\n",
    "importances = []\n",
    "oof = []\n",
    "TRAIN_SUBSAMPLE = 1.0\n",
    "\n",
    "skf = KFold(n_splits = 5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train.target)):\n",
    "\n",
    "    if TRAIN_SUBSAMPLE<1.0:\n",
    "        np.random.seed(42)\n",
    "        train_idx = np.random.choice(train_idx, \n",
    "                       int(len(train_idx)*TRAIN_SUBSAMPLE), replace=False)\n",
    "        np.random.seed(None)\n",
    "        \n",
    "    print('#'*25)\n",
    "    print('### Fold',fold+1)\n",
    "    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n",
    "    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n",
    "    print('#'*25)\n",
    "\n",
    "    X_train = train.loc[train_idx, FEATURES]\n",
    "    y_train = train.loc[train_idx, 'target']\n",
    "    X_valid = train.loc[valid_idx, FEATURES]\n",
    "    y_valid = train.loc[valid_idx, 'target']\n",
    "\n",
    "    dtrain=xgb.DMatrix(X_train, \n",
    "                        y_train)\n",
    "    del X_train, y_train\n",
    "    gc.collect()\n",
    "    d_valid = xgb.DMatrix(X_valid, \n",
    "                        y_valid)\n",
    "    del X_valid\n",
    "    gc.collect()\n",
    "    model = xgb.train(\n",
    "                    xgb_params,\n",
    "                    dtrain=dtrain,\n",
    "                    evals=[(dtrain, 'train'), (d_valid, 'test')],\n",
    "                    num_boost_round= 9999,\n",
    "                    early_stopping_rounds = 100,\n",
    "                    verbose_eval= 100\n",
    "                                                \n",
    "                    )\n",
    "\n",
    "    model.save_model(f'../models/XGB_V_fold{fold}.xgb')\n",
    "    mlflow.xgboost.log_model(model, \"XGBClassifier\")\n",
    "\n",
    "    dd = model.get_score(importance_type='weight')\n",
    "    df= pd.DataFrame({'feature':dd.keys(), f'importance_{fold}':dd.values()})\n",
    "    importances.append(df)\n",
    "    \n",
    "    oof_preds = model.predict(d_valid)\n",
    "    acc = amex_metric(y_valid.values, oof_preds)\n",
    "    mlflow.log_metric(\"Kaggle Metric for XGBClassifier\", acc)\n",
    "\n",
    "    print(\"Kaggle Metric=\", acc,'\\n')\n",
    "\n",
    "    df = train.loc[valid_idx, ['customer_ID', 'target']].copy()\n",
    "    df['oof_pred']= oof_preds\n",
    "    oof.append(df)\n",
    "\n",
    "    del   dd, df\n",
    "    del  d_valid, model\n",
    "    gc.collect()\n",
    "print('#'*25)\n",
    "oof = pd.concat(oof, axis=0, ignore_index=True).set_index('customer_ID')\n",
    "acc= amex_metric(oof.target.values, oof.oof_pred.values)\n",
    "print('OVERAL CV Kaggle Metric = ', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('amex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2402223ceb02c82e09767fed984839ab3646589a63bcb32db44ba9d92921d1b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
