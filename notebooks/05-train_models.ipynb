{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import matplotlib.pyplot as plt, gc, os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import mlflow.lightgbm\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from src.metric import amex_metric\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Woe_balanced dataframe\n",
    "train = pd.read_parquet(\"../data/processed/train_w_labels.parquet\")\n",
    "train=train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_features = pd.read_csv(\"../reports/iv_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.drop('WOE_target',axis=1, inplace=True)\n",
    "FEATURES = iv_features[\"useful\"].to_list()\n",
    "FEATURES.remove(\"target\")\n",
    "FEATURES = FEATURES[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>0.934745</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>1.007647</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>0.880519</td>\n",
       "      <td>6</td>\n",
       "      <td>0.034684</td>\n",
       "      <td>1.004028</td>\n",
       "      <td>0.006911</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>0.880875</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.812649</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>0.621776</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012564</td>\n",
       "      <td>1.006183</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>0.287766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009937</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005560</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>0.871900</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.815746</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID         S_2       P_2  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2018-03-13  0.934745   \n",
       "1  00000fd6641609c6ece5454664794f0340ad84dddce9a2...  2018-03-25  0.880519   \n",
       "2  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...  2018-03-12  0.880875   \n",
       "3  000041bdba6ecadd89a52d11886e8eaaec9325906c9723...  2018-03-29  0.621776   \n",
       "4  00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...  2018-03-30  0.871900   \n",
       "\n",
       "   D_39       B_1       B_2       R_1       S_3  D_41       B_3  ...  D_137  \\\n",
       "0     0  0.009382  1.007647  0.006104  0.135021   0.0  0.007174  ...     -1   \n",
       "1     6  0.034684  1.004028  0.006911  0.165509   0.0  0.005068  ...     -1   \n",
       "2     0  0.004284  0.812649  0.006450       NaN   0.0  0.007196  ...     -1   \n",
       "3     0  0.012564  1.006183  0.007829  0.287766   0.0  0.009937  ...     -1   \n",
       "4     0  0.007679  0.815746  0.001247       NaN   0.0  0.005528  ...     -1   \n",
       "\n",
       "   D_138  D_139  D_140  D_141  D_142  D_143     D_144  D_145  target  \n",
       "0     -1      0      0    0.0    NaN      0  0.002970      0       0  \n",
       "1     -1      0      0    0.0    NaN      0  0.003169      0       0  \n",
       "2     -1      0      0    0.0    NaN      0  0.000834      0       0  \n",
       "3     -1      0      0    0.0    NaN      0  0.005560      0       0  \n",
       "4     -1      0      0    0.0    NaN      0  0.006944      0       0  \n",
       "\n",
       "[5 rows x 191 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "\n",
    "xgb_params = {\n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": 0.055,\n",
    "    #'max_delta_step':3,\n",
    "    #\"subsample\": 0.7,\n",
    "    \"sampling_method\": \"gradient_based\",\n",
    "    # \"lambda\": 0.7,\n",
    "    #\"alpha\": 0.8,\n",
    "    \"tree_method\": \"gpu_hist\",\n",
    "    #\"scale_pos_weight\": 0.25,\n",
    "    # \"max_bin\": 20,\n",
    "    \"colsample_bytree\": 0.6,\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"predictor\": \"gpu_predictor\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting MLFlow\n",
    "experiment_name = \"XGBoost - WoE Balanced + IV Balanced\"\n",
    "try:\n",
    "    exp_id = mlflow.create_experiment(name=experiment_name)\n",
    "except Exception as e:\n",
    "    exp_id = mlflow.get_experiment_by_name(experiment_name).experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = train.columns.to_list()\n",
    "FEATURES.remove(\"target\")\n",
    "FEATURES= FEATURES[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/01 17:13:05 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of xgboost. If you encounter errors during autologging, try upgrading / downgrading xgboost to a supported version, or try upgrading MLflow.\n",
      "2022/11/01 17:13:05 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
      "2022/11/01 17:13:05 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
      "2022/11/01 17:13:05 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "### Train size 367130 Valid size 91783\n",
      "### Training with 100% fold data...\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/01 17:13:06 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'ebb6f585dcf3446091607ede19442a72', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current xgboost workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.66660\ttest-logloss:0.66650\n",
      "[100]\ttrain-logloss:0.28520\ttest-logloss:0.28714\n",
      "[200]\ttrain-logloss:0.26785\ttest-logloss:0.27298\n",
      "[300]\ttrain-logloss:0.26091\ttest-logloss:0.26883\n",
      "[400]\ttrain-logloss:0.25614\ttest-logloss:0.26674\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb#X13sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mdel\u001b[39;00m X_valid\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb#X13sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb#X13sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb#X13sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     xgb_params,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb#X13sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     dtrain\u001b[39m=\u001b[39;49mdtrain,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb#X13sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     evals\u001b[39m=\u001b[39;49m[(dtrain, \u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m), (d_valid, \u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m)],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb#X13sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     num_boost_round\u001b[39m=\u001b[39;49m\u001b[39m9999\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb#X13sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb#X13sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb#X13sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb#X13sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m model\u001b[39m.\u001b[39msave_model(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../models/XGB_Version\u001b[39m\u001b[39m{\u001b[39;00mVERSION\u001b[39m}\u001b[39;00m\u001b[39m_fold\u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m}\u001b[39;00m\u001b[39m.xgb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/victor/Documents/1-DataScience/1-Projetos/1-Default/notebooks/05-train_models.ipynb#X13sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m mlflow\u001b[39m.\u001b[39mxgboost\u001b[39m.\u001b[39mlog_model(model, \u001b[39m\"\u001b[39m\u001b[39mXGBClassifier\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:555\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m     patch_function\u001b[39m.\u001b[39mcall(call_original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     patch_function(call_original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    557\u001b[0m session\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msucceeded\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m try_log_autologging_event(\n\u001b[1;32m    560\u001b[0m     AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_patch_function_success,\n\u001b[1;32m    561\u001b[0m     session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    565\u001b[0m     kwargs,\n\u001b[1;32m    566\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:254\u001b[0m, in \u001b[0;36mwith_managed_run.<locals>.patch_with_managed_run\u001b[0;34m(original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m     managed_run \u001b[39m=\u001b[39m create_managed_run()\n\u001b[1;32m    253\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 254\u001b[0m     result \u001b[39m=\u001b[39m patch_function(original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    255\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m):\n\u001b[1;32m    256\u001b[0m     \u001b[39m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     \u001b[39m# that runs are terminated if a user prematurely interrupts training execution\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     \u001b[39m# (e.g. via sigint / ctrl-c)\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[39mif\u001b[39;00m managed_run:\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/mlflow/xgboost/__init__.py:607\u001b[0m, in \u001b[0;36mautolog.<locals>.train\u001b[0;34m(_log_models, original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m [callback]\n\u001b[1;32m    606\u001b[0m \u001b[39m# training model\u001b[39;00m\n\u001b[0;32m--> 607\u001b[0m model \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    609\u001b[0m \u001b[39m# If early_stopping_rounds is present, logging metrics at the best iteration\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[39m# as extra metrics with the max step + 1.\u001b[39;00m\n\u001b[1;32m    611\u001b[0m early_stopping_index \u001b[39m=\u001b[39m all_arg_names\u001b[39m.\u001b[39mindex(\u001b[39m\"\u001b[39m\u001b[39mearly_stopping_rounds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:536\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[0;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39m_og_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_og_kwargs)\n\u001b[1;32m    534\u001b[0m         \u001b[39mreturn\u001b[39;00m original_result\n\u001b[0;32m--> 536\u001b[0m \u001b[39mreturn\u001b[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:471\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[0;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    463\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    464\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_start,\n\u001b[1;32m    465\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         og_kwargs,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 471\u001b[0m     original_fn_result \u001b[39m=\u001b[39m original_fn(\u001b[39m*\u001b[39;49mog_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mog_kwargs)\n\u001b[1;32m    473\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    474\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_success,\n\u001b[1;32m    475\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    479\u001b[0m         og_kwargs,\n\u001b[1;32m    480\u001b[0m     )\n\u001b[1;32m    481\u001b[0m     \u001b[39mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:533\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[0;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[39m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[39m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[39m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[39m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[39mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[1;32m    530\u001b[0m     disable_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    531\u001b[0m     reroute_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    532\u001b[0m ):\n\u001b[0;32m--> 533\u001b[0m     original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39;49m_og_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_og_kwargs)\n\u001b[1;32m    534\u001b[0m     \u001b[39mreturn\u001b[39;00m original_result\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/1-DataScience/1-Projetos/1-Default/venv/lib/python3.9/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlflow.autolog()\n",
    "importances = []\n",
    "oof = []\n",
    "TRAIN_SUBSAMPLE = 1.0\n",
    "\n",
    "skf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train.target)):\n",
    "\n",
    "    if TRAIN_SUBSAMPLE < 1.0:\n",
    "        np.random.seed(42)\n",
    "        train_idx = np.random.choice(\n",
    "            train_idx, int(len(train_idx) * TRAIN_SUBSAMPLE), replace=False\n",
    "        )\n",
    "        np.random.seed(None)\n",
    "\n",
    "    print(\"#\" * 25)\n",
    "    print(\"### Fold\", fold + 1)\n",
    "    print(\"### Train size\", len(train_idx), \"Valid size\", len(valid_idx))\n",
    "    print(f\"### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...\")\n",
    "    print(\"#\" * 25)\n",
    "\n",
    "    X_train = train.loc[train_idx, FEATURES]\n",
    "    y_train = train.loc[train_idx, \"target\"]\n",
    "    X_valid = train.loc[valid_idx, FEATURES]\n",
    "    y_valid = train.loc[valid_idx, \"target\"]\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    del X_train, y_train\n",
    "    gc.collect()\n",
    "    d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "    del X_valid\n",
    "    gc.collect()\n",
    "    model = xgb.train(\n",
    "        xgb_params,\n",
    "        dtrain=dtrain,\n",
    "        evals=[(dtrain, \"train\"), (d_valid, \"test\")],\n",
    "        num_boost_round=9999,\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=100,\n",
    "    )\n",
    "\n",
    "    model.save_model(f\"../models/XGB_Version{VERSION}_fold{fold}.xgb\")\n",
    "    mlflow.xgboost.log_model(model, \"XGBClassifier\")\n",
    "\n",
    "    dd = model.get_score(importance_type=\"weight\")\n",
    "    df = pd.DataFrame({\"feature\": dd.keys(), f\"importance_{fold}\": dd.values()})\n",
    "    importances.append(df)\n",
    "\n",
    "    oof_preds = model.predict(d_valid)\n",
    "    acc = amex_metric(y_valid.values, oof_preds)\n",
    "    mlflow.log_metric(\"Kaggle Metric for XGBClassifier\", acc)\n",
    "\n",
    "    print(\"Kaggle Metric=\", acc, \"\\n\")\n",
    "\n",
    "    df = train.loc[valid_idx, [\"customer_ID\", \"target\"]].copy()\n",
    "    df[\"oof_pred\"] = oof_preds\n",
    "    oof.append(df)\n",
    "\n",
    "    del dd, df\n",
    "    del d_valid, model\n",
    "    gc.collect()\n",
    "print(\"#\" * 25)\n",
    "oof = pd.concat(oof, axis=0, ignore_index=True).set_index(\"customer_ID\")\n",
    "acc = amex_metric(oof.target.values, oof.oof_pred.values)\n",
    "print(\"OVERAL CV Kaggle Metric = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.system('systemctl poweroff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/01 16:34:53 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of xgboost. If you encounter errors during autologging, try upgrading / downgrading xgboost to a supported version, or try upgrading MLflow.\n",
      "2022/11/01 16:34:53 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
      "2022/11/01 16:34:53 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
      "2022/11/01 16:34:53 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    }
   ],
   "source": [
    "# Setting MLFlow\n",
    "experiment_name = \"RandomForest - WoE Balanced + IV Balanced\"\n",
    "try:\n",
    "    exp_id = mlflow.create_experiment(name=experiment_name)\n",
    "except Exception as e:\n",
    "    exp_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "mlflow.autolog()\n",
    "importances = []\n",
    "oof = []\n",
    "TRAIN_SUBSAMPLE = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "### Train size 367130 Valid size 91783\n",
      "### Training with 100% fold data...\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/01 16:35:45 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 0c5f9edc7c10496681cc710c08010626. Failed operations: [MlflowException(\"Changing param values is not allowed. Param with key=\\'max_depth\\' was already logged with value=\\'4\\' for run ID=\\'0c5f9edc7c10496681cc710c08010626\\'. Attempted logging new value \\'None\\'.\")]')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric= 0.5502397072824545 \n",
      "\n",
      "#########################\n",
      "### Fold 2\n",
      "### Train size 367130 Valid size 91783\n",
      "### Training with 100% fold data...\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/01 16:36:40 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 0c5f9edc7c10496681cc710c08010626. Failed operations: [MlflowException(\"Changing param values is not allowed. Param with key=\\'max_depth\\' was already logged with value=\\'4\\' for run ID=\\'0c5f9edc7c10496681cc710c08010626\\'. Attempted logging new value \\'None\\'.\")]')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric= 0.55571971576264 \n",
      "\n",
      "#########################\n",
      "### Fold 3\n",
      "### Train size 367130 Valid size 91783\n",
      "### Training with 100% fold data...\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/01 16:37:38 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 0c5f9edc7c10496681cc710c08010626. Failed operations: [MlflowException(\"Changing param values is not allowed. Param with key=\\'max_depth\\' was already logged with value=\\'4\\' for run ID=\\'0c5f9edc7c10496681cc710c08010626\\'. Attempted logging new value \\'None\\'.\")]')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric= 0.5629403701937159 \n",
      "\n",
      "#########################\n",
      "### Fold 4\n",
      "### Train size 367131 Valid size 91782\n",
      "### Training with 100% fold data...\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/01 16:38:31 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 0c5f9edc7c10496681cc710c08010626. Failed operations: [MlflowException(\"Changing param values is not allowed. Param with key=\\'max_depth\\' was already logged with value=\\'4\\' for run ID=\\'0c5f9edc7c10496681cc710c08010626\\'. Attempted logging new value \\'None\\'.\")]')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric= 0.5499840840689397 \n",
      "\n",
      "#########################\n",
      "### Fold 5\n",
      "### Train size 367131 Valid size 91782\n",
      "### Training with 100% fold data...\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/01 16:39:25 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 0c5f9edc7c10496681cc710c08010626. Failed operations: [MlflowException(\"Changing param values is not allowed. Param with key=\\'max_depth\\' was already logged with value=\\'4\\' for run ID=\\'0c5f9edc7c10496681cc710c08010626\\'. Attempted logging new value \\'None\\'.\")]')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric= 0.5526674836574395 \n",
      "\n",
      "#########################\n",
      "OVERAL CV Kaggle Metric =  0.5547401981009079\n"
     ]
    }
   ],
   "source": [
    "skf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train.target)):\n",
    "\n",
    "    if TRAIN_SUBSAMPLE < 1.0:\n",
    "        np.random.seed(42)\n",
    "        train_idx = np.random.choice(\n",
    "            train_idx, int(len(train_idx) * TRAIN_SUBSAMPLE), replace=False\n",
    "        )\n",
    "        np.random.seed(None)\n",
    "\n",
    "    print(\"#\" * 25)\n",
    "    print(\"### Fold\", fold + 1)\n",
    "    print(\"### Train size\", len(train_idx), \"Valid size\", len(valid_idx))\n",
    "    print(f\"### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...\")\n",
    "    print(\"#\" * 25)\n",
    "\n",
    "    X_train = train.loc[train_idx, FEATURES]\n",
    "    y_train = train.loc[train_idx, \"target\"]\n",
    "    X_valid = train.loc[valid_idx, FEATURES]\n",
    "    y_valid = train.loc[valid_idx, \"target\"]\n",
    "\n",
    "    model = RandomForestClassifier(n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #model.save_model(f\"../models/RegLog_{VERSION}_fold{fold}.xgb\")\n",
    "    mlflow.sklearn.log_model(model, \"RegLog\")\n",
    "\n",
    "    #dd = model.get_score(importance_type=\"weight\")\n",
    "    # df = pd.DataFrame({\"feature\": dd.keys(), f\"importance_{fold}\": dd.values()})\n",
    "    # importances.append(df)\n",
    "\n",
    "    oof_preds = model.predict(X_valid)\n",
    "    acc = amex_metric(y_valid.values, oof_preds)\n",
    "    mlflow.log_metric(\"Kaggle Metric for RegLog\", acc)\n",
    "\n",
    "    print(\"Kaggle Metric=\", acc, \"\\n\")\n",
    "\n",
    "    df = train.loc[valid_idx, [\"customer_ID\", \"target\"]].copy()\n",
    "    df[\"oof_pred\"] = oof_preds\n",
    "    oof.append(df)\n",
    "\n",
    "    del df\n",
    "    del X_valid, model\n",
    "    gc.collect()\n",
    "print(\"#\" * 25)\n",
    "oof = pd.concat(oof, axis=0, ignore_index=True).set_index(\"customer_ID\")\n",
    "acc = amex_metric(oof.target.values, oof.oof_pred.values)\n",
    "print(\"OVERAL CV Kaggle Metric = \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/01 16:39:29 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of xgboost. If you encounter errors during autologging, try upgrading / downgrading xgboost to a supported version, or try upgrading MLflow.\n",
      "2022/11/01 16:39:29 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
      "2022/11/01 16:39:29 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
      "2022/11/01 16:39:29 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    }
   ],
   "source": [
    "# Setting MLFlow\n",
    "experiment_name = \"RegLog - WoE Balanced + IV Balanced\"\n",
    "try:\n",
    "    exp_id = mlflow.create_experiment(name=experiment_name)\n",
    "except Exception as e:\n",
    "    exp_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "mlflow.autolog()\n",
    "importances = []\n",
    "oof = []\n",
    "TRAIN_SUBSAMPLE = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "### Train size 367130 Valid size 91783\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "Kaggle Metric= 0.5615669116900607 \n",
      "\n",
      "#########################\n",
      "### Fold 2\n",
      "### Train size 367130 Valid size 91783\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "Kaggle Metric= 0.5663568476478444 \n",
      "\n",
      "#########################\n",
      "### Fold 3\n",
      "### Train size 367130 Valid size 91783\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "Kaggle Metric= 0.5638556793607863 \n",
      "\n",
      "#########################\n",
      "### Fold 4\n",
      "### Train size 367131 Valid size 91782\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "Kaggle Metric= 0.5566326166751184 \n",
      "\n",
      "#########################\n",
      "### Fold 5\n",
      "### Train size 367131 Valid size 91782\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "Kaggle Metric= 0.5604082283971887 \n",
      "\n",
      "#########################\n",
      "OVERAL CV Kaggle Metric =  0.5619966622962171\n"
     ]
    }
   ],
   "source": [
    "train.fillna(-127,inplace=True)\n",
    "skf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train.target)):\n",
    "\n",
    "    if TRAIN_SUBSAMPLE < 1.0:\n",
    "        np.random.seed(42)\n",
    "        train_idx = np.random.choice(\n",
    "            train_idx, int(len(train_idx) * TRAIN_SUBSAMPLE), replace=False\n",
    "        )\n",
    "        np.random.seed(None)\n",
    "\n",
    "    print(\"#\" * 25)\n",
    "    print(\"### Fold\", fold + 1)\n",
    "    print(\"### Train size\", len(train_idx), \"Valid size\", len(valid_idx))\n",
    "    print(f\"### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...\")\n",
    "    print(\"#\" * 25)\n",
    "\n",
    "    X_train = train.loc[train_idx, FEATURES]\n",
    "    y_train = train.loc[train_idx, \"target\"]\n",
    "    X_valid = train.loc[valid_idx, FEATURES]\n",
    "    y_valid = train.loc[valid_idx, \"target\"]\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #model.save_model(f\"../models/RegLog_{VERSION}_fold{fold}.xgb\")\n",
    "    mlflow.sklearn.log_model(model, \"RegLog\")\n",
    "\n",
    "    #dd = model.get_score(importance_type=\"weight\")\n",
    "    #df = pd.DataFrame({\"feature\": dd.keys(), f\"importance_{fold}\": dd.values()})\n",
    "    #importances.append(df)\n",
    "\n",
    "    oof_preds = model.predict(X_valid)\n",
    "    acc = amex_metric(y_valid.values, oof_preds)\n",
    "    mlflow.log_metric(\"Kaggle Metric for RegLog\", acc)\n",
    "\n",
    "    print(\"Kaggle Metric=\", acc, \"\\n\")\n",
    "\n",
    "    df = train.loc[valid_idx, [\"customer_ID\", \"target\"]].copy()\n",
    "    df[\"oof_pred\"] = oof_preds\n",
    "    oof.append(df)\n",
    "\n",
    "    del df\n",
    "    del X_valid, model\n",
    "    gc.collect()\n",
    "print(\"#\" * 25)\n",
    "oof = pd.concat(oof, axis=0, ignore_index=True).set_index(\"customer_ID\")\n",
    "acc = amex_metric(oof.target.values, oof.oof_pred.values)\n",
    "print(\"OVERAL CV Kaggle Metric = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a37df45f2b4f5de47e402d1bd750bd56fcb828d129ff4ba544aa48c664b4557b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
