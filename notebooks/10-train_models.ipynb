{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import matplotlib.pyplot as plt, gc, os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import mlflow.lightgbm\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import warnings \n",
    "import xgboost as xgb\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labesl = pd.read_parquet(\"../data/train_iv_balanced.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = labesl.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES.remove(\"target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Woe_balanced dataframe\n",
    "train = pd.read_parquet(\"../data/train_woe_balance_plus_original.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= train.fillna(-127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P_2',\n",
       " 'D_39',\n",
       " 'B_1',\n",
       " 'B_2',\n",
       " 'R_1',\n",
       " 'S_3',\n",
       " 'D_41',\n",
       " 'B_3',\n",
       " 'D_42',\n",
       " 'D_43',\n",
       " 'D_44',\n",
       " 'B_4',\n",
       " 'D_45',\n",
       " 'B_5',\n",
       " 'R_2',\n",
       " 'D_46',\n",
       " 'D_47',\n",
       " 'D_48',\n",
       " 'D_49',\n",
       " 'B_6',\n",
       " 'B_7',\n",
       " 'B_8',\n",
       " 'D_50',\n",
       " 'D_51',\n",
       " 'B_9',\n",
       " 'R_3',\n",
       " 'D_52',\n",
       " 'P_3',\n",
       " 'B_10',\n",
       " 'D_53',\n",
       " 'S_5',\n",
       " 'B_11',\n",
       " 'S_6',\n",
       " 'D_54',\n",
       " 'R_4',\n",
       " 'S_7',\n",
       " 'B_12',\n",
       " 'S_8',\n",
       " 'D_55',\n",
       " 'D_56',\n",
       " 'B_13',\n",
       " 'R_5',\n",
       " 'D_58',\n",
       " 'S_9',\n",
       " 'B_14',\n",
       " 'D_59',\n",
       " 'D_60',\n",
       " 'D_61',\n",
       " 'B_15',\n",
       " 'S_11',\n",
       " 'D_62',\n",
       " 'D_63',\n",
       " 'D_64',\n",
       " 'D_65',\n",
       " 'B_16',\n",
       " 'B_17',\n",
       " 'B_18',\n",
       " 'B_19',\n",
       " 'D_66',\n",
       " 'B_20',\n",
       " 'D_68',\n",
       " 'S_12',\n",
       " 'R_6',\n",
       " 'S_13',\n",
       " 'B_21',\n",
       " 'D_69',\n",
       " 'B_22',\n",
       " 'D_70',\n",
       " 'D_71',\n",
       " 'D_72',\n",
       " 'S_15',\n",
       " 'B_23',\n",
       " 'D_73',\n",
       " 'P_4',\n",
       " 'D_74',\n",
       " 'D_75',\n",
       " 'D_76',\n",
       " 'B_24',\n",
       " 'R_7',\n",
       " 'D_77',\n",
       " 'B_25',\n",
       " 'B_26',\n",
       " 'D_78',\n",
       " 'D_79',\n",
       " 'R_8',\n",
       " 'R_9',\n",
       " 'S_16',\n",
       " 'D_80',\n",
       " 'R_10',\n",
       " 'R_11',\n",
       " 'B_27',\n",
       " 'D_81',\n",
       " 'D_82',\n",
       " 'S_17',\n",
       " 'R_12',\n",
       " 'B_28',\n",
       " 'R_13',\n",
       " 'D_83',\n",
       " 'R_14',\n",
       " 'R_15',\n",
       " 'D_84',\n",
       " 'R_16',\n",
       " 'B_29',\n",
       " 'B_30',\n",
       " 'S_18',\n",
       " 'D_86',\n",
       " 'D_87',\n",
       " 'R_17',\n",
       " 'R_18',\n",
       " 'D_88',\n",
       " 'B_31',\n",
       " 'S_19',\n",
       " 'R_19',\n",
       " 'B_32',\n",
       " 'S_20',\n",
       " 'R_20',\n",
       " 'R_21',\n",
       " 'B_33',\n",
       " 'D_89',\n",
       " 'R_22',\n",
       " 'R_23',\n",
       " 'D_91',\n",
       " 'D_92',\n",
       " 'D_93',\n",
       " 'D_94',\n",
       " 'R_24',\n",
       " 'R_25',\n",
       " 'D_96',\n",
       " 'S_22',\n",
       " 'S_23',\n",
       " 'S_24',\n",
       " 'S_25',\n",
       " 'S_26',\n",
       " 'D_102',\n",
       " 'D_103',\n",
       " 'D_104',\n",
       " 'D_105',\n",
       " 'D_106',\n",
       " 'D_107',\n",
       " 'B_36',\n",
       " 'B_37',\n",
       " 'R_26',\n",
       " 'R_27',\n",
       " 'B_38',\n",
       " 'D_108',\n",
       " 'D_109',\n",
       " 'D_110',\n",
       " 'D_111',\n",
       " 'B_39',\n",
       " 'D_112',\n",
       " 'B_40',\n",
       " 'S_27',\n",
       " 'D_113',\n",
       " 'D_114',\n",
       " 'D_115',\n",
       " 'D_116',\n",
       " 'D_117',\n",
       " 'D_118',\n",
       " 'D_119',\n",
       " 'D_120',\n",
       " 'D_121',\n",
       " 'D_122',\n",
       " 'D_123',\n",
       " 'D_124',\n",
       " 'D_125',\n",
       " 'D_126',\n",
       " 'D_127',\n",
       " 'D_128',\n",
       " 'D_129',\n",
       " 'B_41',\n",
       " 'B_42',\n",
       " 'D_130',\n",
       " 'D_131',\n",
       " 'D_132',\n",
       " 'D_133',\n",
       " 'R_28',\n",
       " 'D_134',\n",
       " 'D_135',\n",
       " 'D_136',\n",
       " 'D_137',\n",
       " 'D_138',\n",
       " 'D_139',\n",
       " 'D_140',\n",
       " 'D_141',\n",
       " 'D_142',\n",
       " 'D_143',\n",
       " 'D_144',\n",
       " 'D_145']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train.drop('WOE_target',axis=1, inplace=True)\n",
    "FEATURES = train.columns.to_list()\n",
    "FEATURES.remove(\"target\")\n",
    "FEATURES = FEATURES[2:]\n",
    "FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Competition metric\n",
    "def amex_metric(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "\n",
    "# xgb_params = {\n",
    "#     'max_depth':4, \n",
    "#     'learning_rate':0.05,\n",
    "#     'subsample': 0.8,\n",
    "#     'colsample_bytree':0.6,\n",
    "#     'eval_metric': 'logloss',\n",
    "#     'objective':'binary:logistic',\n",
    "#     'tree_method':'gpu_hist',\n",
    "#     'predictor':'gpu_predictor',\n",
    "#     'random_state':42\n",
    "# }\n",
    "\n",
    "xgb_params = {\n",
    "        'num_leaves': 10,\n",
    "        'max_bin': 127,\n",
    "        'min_data_in_leaf': 11,\n",
    "        'learning_rate': 0.035,\n",
    "        'bagging_fraction': 1.0, \n",
    "        'bagging_freq': 5, \n",
    "        'feature_fraction': 0.05,\n",
    "        'lambda_l1': 4.972,\n",
    "        'lambda_l2': 2.276,\n",
    "        'min_gain_to_split': 0.65,\n",
    "        'max_depth': 14,\n",
    "        'save_binary': True,\n",
    "        'seed': 1337,\n",
    "        'feature_fraction_seed': 1337,\n",
    "        'bagging_seed': 1337,\n",
    "        'drop_seed': 1337,\n",
    "        'data_random_seed': 1337,\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'dart',\n",
    "        'verbose': 1,\n",
    "        'is_unbalance': True,\n",
    "        'boost_from_average': False,\n",
    "        'device': 'gpu',\n",
    "        'tree_method':'gpu_hist',\n",
    "        'predictor':'gpu_predictor',\n",
    "        'gpu_platform_id': 0,\n",
    "        'gpu_device_id': 0\n",
    "        }\n",
    "\n",
    "reg_log_params={\n",
    "        'penalty': 'l2',\n",
    "        'max_iter': 200,\n",
    "        'warm_start': True,\n",
    "        'n_jobs': 1,\n",
    "            \n",
    "                }\n",
    "fores_params={\n",
    "        'bootstrap': True,\n",
    "        'criterion': 'gini',\n",
    "        'max_depth': 20,\n",
    "        'max_features': 'auto',\n",
    "        'max_leaf_nodes': None,\n",
    "        'min_impurity_decrease': 0.01,\n",
    "        'min_samples_leaf': 1,\n",
    "        'min_samples_split': 2,\n",
    "        'min_weight_fraction_leaf': 0.0,\n",
    "        'n_estimators': 10,\n",
    "        'n_jobs': -1,\n",
    "        'oob_score': False,\n",
    "        'random_state': 42,\n",
    "        'verbose': 0,\n",
    "        'warm_start': False\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting MLFlow\n",
    "experiment_name = \"RegLog, Forest raw dataset\"\n",
    "try:\n",
    "    exp_id = mlflow.create_experiment(name=experiment_name)\n",
    "except Exception as e:\n",
    "    exp_id = mlflow.get_experiment_by_name(experiment_name).experiment_id "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reg Log && Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/29 16:08:29 INFO mlflow.tracking.fluent: Autologging successfully enabled for lightgbm.\n",
      "2022/09/29 16:08:29 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2022/09/29 16:08:29 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "### Train size 4425160 Valid size 1106291\n",
      "### Training model FOREST\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "Kaggle Metric= 0.3829176989456994 \n",
      "\n",
      "Model saved in run a5a0f74153e14cf39db43780d2a7f7d8\n",
      "#########################\n",
      "### Fold 2\n",
      "### Train size 4425161 Valid size 1106290\n",
      "### Training model FOREST\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "Kaggle Metric= 0.3833680140472879 \n",
      "\n",
      "Model saved in run a5a0f74153e14cf39db43780d2a7f7d8\n",
      "#########################\n",
      "### Fold 3\n",
      "### Train size 4425161 Valid size 1106290\n",
      "### Training model FOREST\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "Kaggle Metric= 0.38209591391022013 \n",
      "\n",
      "Model saved in run a5a0f74153e14cf39db43780d2a7f7d8\n",
      "#########################\n",
      "### Fold 4\n",
      "### Train size 4425161 Valid size 1106290\n",
      "### Training model FOREST\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "Kaggle Metric= 0.3827378199067674 \n",
      "\n",
      "Model saved in run a5a0f74153e14cf39db43780d2a7f7d8\n",
      "#########################\n",
      "### Fold 5\n",
      "### Train size 4425161 Valid size 1106290\n",
      "### Training model FOREST\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "Kaggle Metric= 0.3842617587848861 \n",
      "\n",
      "Model saved in run a5a0f74153e14cf39db43780d2a7f7d8\n",
      "#########################\n",
      "OVERAL CV Kaggle Metric for forest = 0.3820932485714743\n"
     ]
    }
   ],
   "source": [
    "mlflow.autolog()\n",
    "\n",
    "modelclasses = [\n",
    "        #[\"reg_log\",LogisticRegression,reg_log_params],\n",
    "        [\"forest\", RandomForestClassifier, fores_params]\n",
    "                ]\n",
    "\n",
    "# TRAIN RANDOM SEED\n",
    "SEED = 42\n",
    "\n",
    "# FILL NAN VALUE\n",
    "NAN_VALUE = -127 # will fit in int8\n",
    "\n",
    "# FOLDS PER MODEL\n",
    "FOLDS = 5\n",
    "\n",
    "\n",
    "importances = []\n",
    "oof = []\n",
    "TRAIN_SUBSAMPLE = 1.0\n",
    "\n",
    "skf = KFold(n_splits = FOLDS, shuffle=True, random_state=42)\n",
    "with mlflow.start_run(experiment_id=exp_id):\n",
    "        for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train.target)):\n",
    "                \n",
    "\n",
    "                if TRAIN_SUBSAMPLE<1.0:\n",
    "                        np.random.seed(SEED)\n",
    "                        train_idx = np.random.choice(train_idx, \n",
    "                                        int(len(train_idx)*TRAIN_SUBSAMPLE), replace=False)\n",
    "                        np.random.seed(None)\n",
    "                \n",
    "                X_train = train.loc[train_idx, FEATURES]\n",
    "                y_train = train.loc[train_idx, 'target']\n",
    "                X_valid = train.loc[valid_idx, FEATURES]\n",
    "                y_valid = train.loc[valid_idx, 'target']\n",
    "\n",
    "                for modelname, Model, param_list in modelclasses:\n",
    "                        print('#'*25)\n",
    "                        print('### Fold',fold+1)\n",
    "                        print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n",
    "                        print(f'### Training model {modelname.upper()}')\n",
    "                        print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n",
    "                        print('#'*25)\n",
    "\n",
    "                        model = Model(**param_list)\n",
    "                        #print(model)\n",
    "                        model.fit(X_train,y_train)\n",
    "\n",
    "                        pickle.dump(model, open(f'../models/{modelname}_fold{fold}.pkl','wb'))\n",
    "\n",
    "                        oof_preds = model.predict(X_valid)\n",
    "                        acc = amex_metric(y_valid.values, oof_preds)\n",
    "                        print(\"Kaggle Metric=\", acc,'\\n')\n",
    "                        mlflow.log_metric(f\"Kaggle Metric for {modelname}\", acc)\n",
    "                        mlflow.sklearn.log_model(model, f\"{Model}\")\n",
    "                        print(\"Model saved in run %s\" % mlflow.active_run().info.run_uuid)\n",
    "                        \n",
    "                        mlflow.sklearn.log_model(model, f\"{Model}\")\n",
    "                        df = train.loc[valid_idx, ['customer_ID', 'target']].copy()\n",
    "                        df['oof_pred']= oof_preds\n",
    "                        df['model_name'] = modelname\n",
    "                        oof.append(df)\n",
    "\n",
    "                        del df, model\n",
    "\n",
    "                del X_train, y_train\n",
    "                del X_valid, y_valid\n",
    "\n",
    "        \n",
    "print('#'*25)\n",
    "oof = pd.concat(oof, axis=0, ignore_index=True).set_index('customer_ID')\n",
    "for n in range(len(modelclasses)):\n",
    "    target = oof.loc[oof['model_name'] ==modelclasses[n][0], ['target'] ].reset_index()\n",
    "    preds = oof.loc[oof['model_name'] == modelclasses[n][0], ['oof_pred']].reset_index()\n",
    "    acc= amex_metric(target.target.values, preds.oof_pred.values)\n",
    "    print(f'OVERAL CV Kaggle Metric for {modelclasses[n][0]} = {acc}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting MLFlow\n",
    "experiment_name = \"XGBoost - WoE Balanced + IV Balanced\"\n",
    "try:\n",
    "    exp_id = mlflow.create_experiment(name=experiment_name)\n",
    "except Exception as e:\n",
    "    exp_id = mlflow.get_experiment_by_name(experiment_name).experiment_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/29 16:17:55 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2022/09/29 16:17:55 INFO mlflow.tracking.fluent: Autologging successfully enabled for lightgbm.\n",
      "2022/09/29 16:17:55 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "### Train size 4425160 Valid size 1106291\n",
      "### Training with 100% fold data...\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/29 16:18:11 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b17463ab9c114583997aa80e2db8573d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current xgboost workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.66626\ttest-logloss:0.66628\n",
      "[100]\ttrain-logloss:0.28711\ttest-logloss:0.28713\n",
      "[200]\ttrain-logloss:0.27706\ttest-logloss:0.27715\n",
      "[300]\ttrain-logloss:0.27303\ttest-logloss:0.27325\n",
      "[400]\ttrain-logloss:0.27069\ttest-logloss:0.27099\n",
      "[500]\ttrain-logloss:0.26908\ttest-logloss:0.26946\n",
      "[600]\ttrain-logloss:0.26781\ttest-logloss:0.26830\n",
      "[700]\ttrain-logloss:0.26681\ttest-logloss:0.26741\n",
      "[800]\ttrain-logloss:0.26595\ttest-logloss:0.26663\n",
      "[900]\ttrain-logloss:0.26518\ttest-logloss:0.26595\n",
      "[1000]\ttrain-logloss:0.26452\ttest-logloss:0.26539\n",
      "[1100]\ttrain-logloss:0.26392\ttest-logloss:0.26487\n",
      "[1200]\ttrain-logloss:0.26337\ttest-logloss:0.26440\n",
      "[1300]\ttrain-logloss:0.26287\ttest-logloss:0.26400\n",
      "[1400]\ttrain-logloss:0.26239\ttest-logloss:0.26361\n",
      "[1500]\ttrain-logloss:0.26195\ttest-logloss:0.26325\n",
      "[1600]\ttrain-logloss:0.26152\ttest-logloss:0.26290\n",
      "[1700]\ttrain-logloss:0.26111\ttest-logloss:0.26259\n",
      "[1800]\ttrain-logloss:0.26070\ttest-logloss:0.26228\n",
      "[1900]\ttrain-logloss:0.26032\ttest-logloss:0.26198\n",
      "[2000]\ttrain-logloss:0.25995\ttest-logloss:0.26169\n",
      "[2100]\ttrain-logloss:0.25960\ttest-logloss:0.26143\n",
      "[2200]\ttrain-logloss:0.25926\ttest-logloss:0.26117\n",
      "[2300]\ttrain-logloss:0.25893\ttest-logloss:0.26093\n",
      "[2400]\ttrain-logloss:0.25860\ttest-logloss:0.26067\n",
      "[2500]\ttrain-logloss:0.25828\ttest-logloss:0.26044\n",
      "[2600]\ttrain-logloss:0.25798\ttest-logloss:0.26022\n",
      "[2700]\ttrain-logloss:0.25768\ttest-logloss:0.26000\n",
      "[2800]\ttrain-logloss:0.25738\ttest-logloss:0.25979\n",
      "[2900]\ttrain-logloss:0.25709\ttest-logloss:0.25959\n",
      "[3000]\ttrain-logloss:0.25680\ttest-logloss:0.25938\n",
      "[3100]\ttrain-logloss:0.25651\ttest-logloss:0.25917\n",
      "[3200]\ttrain-logloss:0.25624\ttest-logloss:0.25897\n",
      "[3300]\ttrain-logloss:0.25596\ttest-logloss:0.25878\n",
      "[3400]\ttrain-logloss:0.25571\ttest-logloss:0.25861\n",
      "[3500]\ttrain-logloss:0.25544\ttest-logloss:0.25843\n",
      "[3600]\ttrain-logloss:0.25518\ttest-logloss:0.25824\n",
      "[3700]\ttrain-logloss:0.25492\ttest-logloss:0.25807\n",
      "[3800]\ttrain-logloss:0.25467\ttest-logloss:0.25790\n",
      "[3900]\ttrain-logloss:0.25442\ttest-logloss:0.25773\n",
      "[4000]\ttrain-logloss:0.25416\ttest-logloss:0.25755\n",
      "[4100]\ttrain-logloss:0.25392\ttest-logloss:0.25738\n",
      "[4200]\ttrain-logloss:0.25366\ttest-logloss:0.25721\n",
      "[4300]\ttrain-logloss:0.25344\ttest-logloss:0.25705\n",
      "[4400]\ttrain-logloss:0.25320\ttest-logloss:0.25689\n",
      "[4500]\ttrain-logloss:0.25297\ttest-logloss:0.25674\n",
      "[4600]\ttrain-logloss:0.25274\ttest-logloss:0.25659\n",
      "[4700]\ttrain-logloss:0.25250\ttest-logloss:0.25643\n",
      "[4800]\ttrain-logloss:0.25227\ttest-logloss:0.25629\n",
      "[4900]\ttrain-logloss:0.25204\ttest-logloss:0.25613\n",
      "[5000]\ttrain-logloss:0.25182\ttest-logloss:0.25598\n",
      "[5100]\ttrain-logloss:0.25159\ttest-logloss:0.25583\n",
      "[5200]\ttrain-logloss:0.25137\ttest-logloss:0.25568\n",
      "[5300]\ttrain-logloss:0.25115\ttest-logloss:0.25553\n",
      "[5400]\ttrain-logloss:0.25093\ttest-logloss:0.25541\n",
      "[5500]\ttrain-logloss:0.25072\ttest-logloss:0.25527\n",
      "[5600]\ttrain-logloss:0.25050\ttest-logloss:0.25512\n",
      "[5700]\ttrain-logloss:0.25029\ttest-logloss:0.25498\n",
      "[5800]\ttrain-logloss:0.25008\ttest-logloss:0.25485\n",
      "[5900]\ttrain-logloss:0.24987\ttest-logloss:0.25471\n",
      "[6000]\ttrain-logloss:0.24966\ttest-logloss:0.25456\n",
      "[6100]\ttrain-logloss:0.24945\ttest-logloss:0.25443\n",
      "[6200]\ttrain-logloss:0.24924\ttest-logloss:0.25430\n",
      "[6300]\ttrain-logloss:0.24903\ttest-logloss:0.25417\n",
      "[6400]\ttrain-logloss:0.24883\ttest-logloss:0.25405\n",
      "[6500]\ttrain-logloss:0.24863\ttest-logloss:0.25391\n",
      "[6600]\ttrain-logloss:0.24843\ttest-logloss:0.25378\n",
      "[6700]\ttrain-logloss:0.24823\ttest-logloss:0.25366\n",
      "[6800]\ttrain-logloss:0.24802\ttest-logloss:0.25352\n",
      "[6900]\ttrain-logloss:0.24783\ttest-logloss:0.25340\n",
      "[7000]\ttrain-logloss:0.24764\ttest-logloss:0.25328\n",
      "[7100]\ttrain-logloss:0.24744\ttest-logloss:0.25315\n",
      "[7200]\ttrain-logloss:0.24725\ttest-logloss:0.25303\n",
      "[7300]\ttrain-logloss:0.24706\ttest-logloss:0.25291\n",
      "[7400]\ttrain-logloss:0.24686\ttest-logloss:0.25279\n",
      "[7500]\ttrain-logloss:0.24668\ttest-logloss:0.25267\n",
      "[7600]\ttrain-logloss:0.24648\ttest-logloss:0.25254\n",
      "[7700]\ttrain-logloss:0.24628\ttest-logloss:0.25241\n",
      "[7800]\ttrain-logloss:0.24609\ttest-logloss:0.25229\n",
      "[7900]\ttrain-logloss:0.24591\ttest-logloss:0.25217\n",
      "[8000]\ttrain-logloss:0.24571\ttest-logloss:0.25206\n",
      "[8100]\ttrain-logloss:0.24552\ttest-logloss:0.25194\n",
      "[8200]\ttrain-logloss:0.24534\ttest-logloss:0.25183\n",
      "[8300]\ttrain-logloss:0.24515\ttest-logloss:0.25171\n",
      "[8400]\ttrain-logloss:0.24497\ttest-logloss:0.25159\n",
      "[8500]\ttrain-logloss:0.24479\ttest-logloss:0.25148\n",
      "[8600]\ttrain-logloss:0.24461\ttest-logloss:0.25137\n",
      "[8700]\ttrain-logloss:0.24444\ttest-logloss:0.25125\n",
      "[8800]\ttrain-logloss:0.24427\ttest-logloss:0.25115\n",
      "[8900]\ttrain-logloss:0.24409\ttest-logloss:0.25104\n",
      "[9000]\ttrain-logloss:0.24391\ttest-logloss:0.25092\n",
      "[9100]\ttrain-logloss:0.24373\ttest-logloss:0.25081\n",
      "[9200]\ttrain-logloss:0.24355\ttest-logloss:0.25070\n",
      "[9300]\ttrain-logloss:0.24338\ttest-logloss:0.25059\n",
      "[9400]\ttrain-logloss:0.24320\ttest-logloss:0.25048\n",
      "[9500]\ttrain-logloss:0.24303\ttest-logloss:0.25038\n",
      "[9600]\ttrain-logloss:0.24286\ttest-logloss:0.25027\n",
      "[9700]\ttrain-logloss:0.24269\ttest-logloss:0.25016\n",
      "[9800]\ttrain-logloss:0.24251\ttest-logloss:0.25004\n",
      "[9900]\ttrain-logloss:0.24233\ttest-logloss:0.24993\n",
      "[9998]\ttrain-logloss:0.24218\ttest-logloss:0.24985\n",
      "Kaggle Metric= 0.7327924801129948 \n",
      "\n",
      "#########################\n",
      "### Fold 2\n",
      "### Train size 4425161 Valid size 1106290\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "[0]\ttrain-logloss:0.66628\ttest-logloss:0.66624\n",
      "[100]\ttrain-logloss:0.28726\ttest-logloss:0.28625\n",
      "[200]\ttrain-logloss:0.27723\ttest-logloss:0.27640\n",
      "[300]\ttrain-logloss:0.27326\ttest-logloss:0.27255\n",
      "[400]\ttrain-logloss:0.27088\ttest-logloss:0.27028\n",
      "[500]\ttrain-logloss:0.26927\ttest-logloss:0.26875\n",
      "[600]\ttrain-logloss:0.26802\ttest-logloss:0.26760\n",
      "[700]\ttrain-logloss:0.26704\ttest-logloss:0.26670\n",
      "[800]\ttrain-logloss:0.26619\ttest-logloss:0.26593\n",
      "[900]\ttrain-logloss:0.26545\ttest-logloss:0.26526\n",
      "[1000]\ttrain-logloss:0.26481\ttest-logloss:0.26468\n",
      "[1100]\ttrain-logloss:0.26423\ttest-logloss:0.26418\n",
      "[1200]\ttrain-logloss:0.26370\ttest-logloss:0.26372\n",
      "[1300]\ttrain-logloss:0.26319\ttest-logloss:0.26329\n",
      "[1400]\ttrain-logloss:0.26272\ttest-logloss:0.26289\n",
      "[1500]\ttrain-logloss:0.26228\ttest-logloss:0.26253\n",
      "[1600]\ttrain-logloss:0.26186\ttest-logloss:0.26218\n",
      "[1700]\ttrain-logloss:0.26143\ttest-logloss:0.26182\n",
      "[1800]\ttrain-logloss:0.26104\ttest-logloss:0.26150\n",
      "[1900]\ttrain-logloss:0.26065\ttest-logloss:0.26121\n",
      "[2000]\ttrain-logloss:0.26029\ttest-logloss:0.26093\n",
      "[2100]\ttrain-logloss:0.25996\ttest-logloss:0.26067\n",
      "[2200]\ttrain-logloss:0.25960\ttest-logloss:0.26039\n",
      "[2300]\ttrain-logloss:0.25927\ttest-logloss:0.26015\n",
      "[2400]\ttrain-logloss:0.25894\ttest-logloss:0.25989\n",
      "[2500]\ttrain-logloss:0.25864\ttest-logloss:0.25966\n",
      "[2600]\ttrain-logloss:0.25833\ttest-logloss:0.25943\n",
      "[2700]\ttrain-logloss:0.25803\ttest-logloss:0.25921\n",
      "[2800]\ttrain-logloss:0.25774\ttest-logloss:0.25900\n",
      "[2900]\ttrain-logloss:0.25745\ttest-logloss:0.25877\n",
      "[3000]\ttrain-logloss:0.25716\ttest-logloss:0.25857\n",
      "[3100]\ttrain-logloss:0.25687\ttest-logloss:0.25834\n",
      "[3200]\ttrain-logloss:0.25659\ttest-logloss:0.25813\n",
      "[3300]\ttrain-logloss:0.25630\ttest-logloss:0.25793\n",
      "[3400]\ttrain-logloss:0.25603\ttest-logloss:0.25773\n",
      "[3500]\ttrain-logloss:0.25578\ttest-logloss:0.25755\n",
      "[3600]\ttrain-logloss:0.25552\ttest-logloss:0.25738\n",
      "[3700]\ttrain-logloss:0.25526\ttest-logloss:0.25720\n",
      "[3800]\ttrain-logloss:0.25499\ttest-logloss:0.25700\n",
      "[3900]\ttrain-logloss:0.25475\ttest-logloss:0.25683\n",
      "[4000]\ttrain-logloss:0.25448\ttest-logloss:0.25664\n",
      "[4100]\ttrain-logloss:0.25423\ttest-logloss:0.25645\n",
      "[4200]\ttrain-logloss:0.25399\ttest-logloss:0.25629\n",
      "[4300]\ttrain-logloss:0.25374\ttest-logloss:0.25611\n",
      "[4400]\ttrain-logloss:0.25350\ttest-logloss:0.25595\n",
      "[4500]\ttrain-logloss:0.25326\ttest-logloss:0.25578\n",
      "[4600]\ttrain-logloss:0.25303\ttest-logloss:0.25562\n",
      "[4700]\ttrain-logloss:0.25279\ttest-logloss:0.25546\n",
      "[4800]\ttrain-logloss:0.25258\ttest-logloss:0.25533\n",
      "[4900]\ttrain-logloss:0.25235\ttest-logloss:0.25518\n",
      "[5000]\ttrain-logloss:0.25213\ttest-logloss:0.25503\n",
      "[5100]\ttrain-logloss:0.25190\ttest-logloss:0.25488\n",
      "[5200]\ttrain-logloss:0.25167\ttest-logloss:0.25472\n",
      "[5300]\ttrain-logloss:0.25144\ttest-logloss:0.25456\n",
      "[5400]\ttrain-logloss:0.25122\ttest-logloss:0.25441\n",
      "[5500]\ttrain-logloss:0.25101\ttest-logloss:0.25428\n",
      "[5600]\ttrain-logloss:0.25080\ttest-logloss:0.25414\n",
      "[5700]\ttrain-logloss:0.25059\ttest-logloss:0.25400\n",
      "[5800]\ttrain-logloss:0.25038\ttest-logloss:0.25387\n",
      "[5900]\ttrain-logloss:0.25016\ttest-logloss:0.25370\n",
      "[6000]\ttrain-logloss:0.24995\ttest-logloss:0.25357\n",
      "[6100]\ttrain-logloss:0.24974\ttest-logloss:0.25342\n",
      "[6200]\ttrain-logloss:0.24954\ttest-logloss:0.25329\n",
      "[6300]\ttrain-logloss:0.24933\ttest-logloss:0.25316\n",
      "[6400]\ttrain-logloss:0.24913\ttest-logloss:0.25303\n",
      "[6500]\ttrain-logloss:0.24894\ttest-logloss:0.25291\n",
      "[6600]\ttrain-logloss:0.24873\ttest-logloss:0.25277\n",
      "[6700]\ttrain-logloss:0.24854\ttest-logloss:0.25265\n",
      "[6800]\ttrain-logloss:0.24834\ttest-logloss:0.25253\n",
      "[6900]\ttrain-logloss:0.24814\ttest-logloss:0.25240\n",
      "[7000]\ttrain-logloss:0.24794\ttest-logloss:0.25226\n",
      "[7100]\ttrain-logloss:0.24776\ttest-logloss:0.25215\n",
      "[7200]\ttrain-logloss:0.24756\ttest-logloss:0.25203\n",
      "[7300]\ttrain-logloss:0.24737\ttest-logloss:0.25190\n",
      "[7400]\ttrain-logloss:0.24719\ttest-logloss:0.25178\n",
      "[7500]\ttrain-logloss:0.24699\ttest-logloss:0.25165\n",
      "[7600]\ttrain-logloss:0.24681\ttest-logloss:0.25153\n",
      "[7700]\ttrain-logloss:0.24661\ttest-logloss:0.25140\n",
      "[7800]\ttrain-logloss:0.24643\ttest-logloss:0.25129\n",
      "[7900]\ttrain-logloss:0.24624\ttest-logloss:0.25118\n",
      "[8000]\ttrain-logloss:0.24605\ttest-logloss:0.25105\n",
      "[8100]\ttrain-logloss:0.24588\ttest-logloss:0.25095\n",
      "[8200]\ttrain-logloss:0.24570\ttest-logloss:0.25084\n",
      "[8300]\ttrain-logloss:0.24552\ttest-logloss:0.25073\n",
      "[8400]\ttrain-logloss:0.24533\ttest-logloss:0.25061\n",
      "[8500]\ttrain-logloss:0.24515\ttest-logloss:0.25050\n",
      "[8600]\ttrain-logloss:0.24497\ttest-logloss:0.25038\n",
      "[8700]\ttrain-logloss:0.24480\ttest-logloss:0.25028\n",
      "[8800]\ttrain-logloss:0.24462\ttest-logloss:0.25017\n",
      "[8900]\ttrain-logloss:0.24445\ttest-logloss:0.25006\n",
      "[9000]\ttrain-logloss:0.24427\ttest-logloss:0.24996\n",
      "[9100]\ttrain-logloss:0.24411\ttest-logloss:0.24986\n",
      "[9200]\ttrain-logloss:0.24392\ttest-logloss:0.24974\n",
      "[9300]\ttrain-logloss:0.24375\ttest-logloss:0.24964\n",
      "[9400]\ttrain-logloss:0.24359\ttest-logloss:0.24955\n",
      "[9500]\ttrain-logloss:0.24342\ttest-logloss:0.24945\n",
      "[9600]\ttrain-logloss:0.24325\ttest-logloss:0.24934\n",
      "[9700]\ttrain-logloss:0.24308\ttest-logloss:0.24923\n",
      "[9800]\ttrain-logloss:0.24291\ttest-logloss:0.24913\n",
      "[9900]\ttrain-logloss:0.24274\ttest-logloss:0.24902\n",
      "[9998]\ttrain-logloss:0.24258\ttest-logloss:0.24892\n",
      "Kaggle Metric= 0.7351990065963206 \n",
      "\n",
      "#########################\n",
      "### Fold 3\n",
      "### Train size 4425161 Valid size 1106290\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "[0]\ttrain-logloss:0.66626\ttest-logloss:0.66629\n",
      "[100]\ttrain-logloss:0.28707\ttest-logloss:0.28742\n",
      "[200]\ttrain-logloss:0.27704\ttest-logloss:0.27738\n",
      "[300]\ttrain-logloss:0.27302\ttest-logloss:0.27346\n",
      "[400]\ttrain-logloss:0.27063\ttest-logloss:0.27115\n",
      "[500]\ttrain-logloss:0.26903\ttest-logloss:0.26963\n",
      "[600]\ttrain-logloss:0.26775\ttest-logloss:0.26845\n",
      "[700]\ttrain-logloss:0.26675\ttest-logloss:0.26753\n",
      "[800]\ttrain-logloss:0.26592\ttest-logloss:0.26678\n",
      "[900]\ttrain-logloss:0.26517\ttest-logloss:0.26611\n",
      "[1000]\ttrain-logloss:0.26452\ttest-logloss:0.26555\n",
      "[1100]\ttrain-logloss:0.26392\ttest-logloss:0.26503\n",
      "[1200]\ttrain-logloss:0.26339\ttest-logloss:0.26459\n",
      "[1300]\ttrain-logloss:0.26288\ttest-logloss:0.26417\n",
      "[1400]\ttrain-logloss:0.26239\ttest-logloss:0.26377\n",
      "[1500]\ttrain-logloss:0.26195\ttest-logloss:0.26343\n",
      "[1600]\ttrain-logloss:0.26152\ttest-logloss:0.26308\n",
      "[1700]\ttrain-logloss:0.26112\ttest-logloss:0.26276\n",
      "[1800]\ttrain-logloss:0.26072\ttest-logloss:0.26247\n",
      "[1900]\ttrain-logloss:0.26035\ttest-logloss:0.26218\n",
      "[2000]\ttrain-logloss:0.26000\ttest-logloss:0.26191\n",
      "[2100]\ttrain-logloss:0.25966\ttest-logloss:0.26165\n",
      "[2200]\ttrain-logloss:0.25930\ttest-logloss:0.26139\n",
      "[2300]\ttrain-logloss:0.25898\ttest-logloss:0.26115\n",
      "[2400]\ttrain-logloss:0.25867\ttest-logloss:0.26091\n",
      "[2500]\ttrain-logloss:0.25837\ttest-logloss:0.26069\n",
      "[2600]\ttrain-logloss:0.25805\ttest-logloss:0.26047\n",
      "[2700]\ttrain-logloss:0.25775\ttest-logloss:0.26024\n",
      "[2800]\ttrain-logloss:0.25746\ttest-logloss:0.26004\n",
      "[2900]\ttrain-logloss:0.25717\ttest-logloss:0.25983\n",
      "[3000]\ttrain-logloss:0.25687\ttest-logloss:0.25961\n",
      "[3100]\ttrain-logloss:0.25658\ttest-logloss:0.25941\n",
      "[3200]\ttrain-logloss:0.25632\ttest-logloss:0.25922\n",
      "[3300]\ttrain-logloss:0.25603\ttest-logloss:0.25902\n",
      "[3400]\ttrain-logloss:0.25576\ttest-logloss:0.25883\n",
      "[3500]\ttrain-logloss:0.25551\ttest-logloss:0.25866\n",
      "[3600]\ttrain-logloss:0.25523\ttest-logloss:0.25847\n",
      "[3700]\ttrain-logloss:0.25495\ttest-logloss:0.25827\n",
      "[3800]\ttrain-logloss:0.25469\ttest-logloss:0.25809\n",
      "[3900]\ttrain-logloss:0.25444\ttest-logloss:0.25792\n",
      "[4000]\ttrain-logloss:0.25420\ttest-logloss:0.25775\n",
      "[4100]\ttrain-logloss:0.25395\ttest-logloss:0.25759\n",
      "[4200]\ttrain-logloss:0.25371\ttest-logloss:0.25742\n",
      "[4300]\ttrain-logloss:0.25347\ttest-logloss:0.25726\n",
      "[4400]\ttrain-logloss:0.25323\ttest-logloss:0.25709\n",
      "[4500]\ttrain-logloss:0.25298\ttest-logloss:0.25693\n",
      "[4600]\ttrain-logloss:0.25274\ttest-logloss:0.25676\n",
      "[4700]\ttrain-logloss:0.25251\ttest-logloss:0.25661\n",
      "[4800]\ttrain-logloss:0.25228\ttest-logloss:0.25645\n",
      "[4900]\ttrain-logloss:0.25206\ttest-logloss:0.25631\n",
      "[5000]\ttrain-logloss:0.25183\ttest-logloss:0.25616\n",
      "[5100]\ttrain-logloss:0.25161\ttest-logloss:0.25601\n",
      "[5200]\ttrain-logloss:0.25139\ttest-logloss:0.25588\n",
      "[5300]\ttrain-logloss:0.25117\ttest-logloss:0.25573\n",
      "[5400]\ttrain-logloss:0.25095\ttest-logloss:0.25559\n",
      "[5500]\ttrain-logloss:0.25073\ttest-logloss:0.25544\n",
      "[5600]\ttrain-logloss:0.25052\ttest-logloss:0.25531\n",
      "[5700]\ttrain-logloss:0.25030\ttest-logloss:0.25516\n",
      "[5800]\ttrain-logloss:0.25008\ttest-logloss:0.25501\n",
      "[5900]\ttrain-logloss:0.24988\ttest-logloss:0.25489\n",
      "[6000]\ttrain-logloss:0.24969\ttest-logloss:0.25476\n",
      "[6100]\ttrain-logloss:0.24948\ttest-logloss:0.25463\n",
      "[6200]\ttrain-logloss:0.24927\ttest-logloss:0.25449\n",
      "[6300]\ttrain-logloss:0.24906\ttest-logloss:0.25436\n",
      "[6400]\ttrain-logloss:0.24886\ttest-logloss:0.25423\n",
      "[6500]\ttrain-logloss:0.24867\ttest-logloss:0.25410\n",
      "[6600]\ttrain-logloss:0.24848\ttest-logloss:0.25399\n",
      "[6700]\ttrain-logloss:0.24828\ttest-logloss:0.25387\n",
      "[6800]\ttrain-logloss:0.24808\ttest-logloss:0.25374\n",
      "[6900]\ttrain-logloss:0.24789\ttest-logloss:0.25363\n",
      "[7000]\ttrain-logloss:0.24769\ttest-logloss:0.25350\n",
      "[7100]\ttrain-logloss:0.24750\ttest-logloss:0.25338\n",
      "[7200]\ttrain-logloss:0.24730\ttest-logloss:0.25326\n",
      "[7300]\ttrain-logloss:0.24711\ttest-logloss:0.25313\n",
      "[7400]\ttrain-logloss:0.24692\ttest-logloss:0.25301\n",
      "[7500]\ttrain-logloss:0.24674\ttest-logloss:0.25290\n",
      "[7600]\ttrain-logloss:0.24655\ttest-logloss:0.25278\n",
      "[7700]\ttrain-logloss:0.24637\ttest-logloss:0.25267\n",
      "[7800]\ttrain-logloss:0.24619\ttest-logloss:0.25256\n",
      "[7900]\ttrain-logloss:0.24599\ttest-logloss:0.25243\n",
      "[8000]\ttrain-logloss:0.24581\ttest-logloss:0.25231\n",
      "[8100]\ttrain-logloss:0.24563\ttest-logloss:0.25219\n",
      "[8200]\ttrain-logloss:0.24543\ttest-logloss:0.25206\n",
      "[8300]\ttrain-logloss:0.24524\ttest-logloss:0.25194\n",
      "[8400]\ttrain-logloss:0.24506\ttest-logloss:0.25182\n",
      "[8500]\ttrain-logloss:0.24488\ttest-logloss:0.25171\n",
      "[8600]\ttrain-logloss:0.24470\ttest-logloss:0.25160\n",
      "[8700]\ttrain-logloss:0.24452\ttest-logloss:0.25148\n",
      "[8800]\ttrain-logloss:0.24433\ttest-logloss:0.25137\n",
      "[8900]\ttrain-logloss:0.24416\ttest-logloss:0.25126\n",
      "[9000]\ttrain-logloss:0.24398\ttest-logloss:0.25115\n",
      "[9100]\ttrain-logloss:0.24380\ttest-logloss:0.25105\n",
      "[9200]\ttrain-logloss:0.24363\ttest-logloss:0.25093\n",
      "[9300]\ttrain-logloss:0.24345\ttest-logloss:0.25082\n",
      "[9400]\ttrain-logloss:0.24328\ttest-logloss:0.25071\n",
      "[9500]\ttrain-logloss:0.24311\ttest-logloss:0.25061\n",
      "[9600]\ttrain-logloss:0.24294\ttest-logloss:0.25051\n",
      "[9700]\ttrain-logloss:0.24277\ttest-logloss:0.25041\n",
      "[9800]\ttrain-logloss:0.24259\ttest-logloss:0.25030\n",
      "[9900]\ttrain-logloss:0.24242\ttest-logloss:0.25019\n",
      "[9998]\ttrain-logloss:0.24226\ttest-logloss:0.25009\n",
      "Kaggle Metric= 0.7327054153812687 \n",
      "\n",
      "#########################\n",
      "### Fold 4\n",
      "### Train size 4425161 Valid size 1106290\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "[0]\ttrain-logloss:0.66628\ttest-logloss:0.66626\n",
      "[100]\ttrain-logloss:0.28695\ttest-logloss:0.28757\n",
      "[200]\ttrain-logloss:0.27694\ttest-logloss:0.27773\n",
      "[300]\ttrain-logloss:0.27294\ttest-logloss:0.27384\n",
      "[400]\ttrain-logloss:0.27057\ttest-logloss:0.27155\n",
      "[500]\ttrain-logloss:0.26894\ttest-logloss:0.27002\n",
      "[600]\ttrain-logloss:0.26768\ttest-logloss:0.26887\n",
      "[700]\ttrain-logloss:0.26665\ttest-logloss:0.26795\n",
      "[800]\ttrain-logloss:0.26581\ttest-logloss:0.26722\n",
      "[900]\ttrain-logloss:0.26507\ttest-logloss:0.26657\n",
      "[1000]\ttrain-logloss:0.26443\ttest-logloss:0.26603\n",
      "[1100]\ttrain-logloss:0.26381\ttest-logloss:0.26552\n",
      "[1200]\ttrain-logloss:0.26328\ttest-logloss:0.26508\n",
      "[1300]\ttrain-logloss:0.26280\ttest-logloss:0.26468\n",
      "[1400]\ttrain-logloss:0.26232\ttest-logloss:0.26429\n",
      "[1500]\ttrain-logloss:0.26185\ttest-logloss:0.26391\n",
      "[1600]\ttrain-logloss:0.26143\ttest-logloss:0.26358\n",
      "[1700]\ttrain-logloss:0.26101\ttest-logloss:0.26324\n",
      "[1800]\ttrain-logloss:0.26059\ttest-logloss:0.26292\n",
      "[1900]\ttrain-logloss:0.26024\ttest-logloss:0.26265\n",
      "[2000]\ttrain-logloss:0.25988\ttest-logloss:0.26238\n",
      "[2100]\ttrain-logloss:0.25954\ttest-logloss:0.26214\n",
      "[2200]\ttrain-logloss:0.25919\ttest-logloss:0.26187\n",
      "[2300]\ttrain-logloss:0.25886\ttest-logloss:0.26163\n",
      "[2400]\ttrain-logloss:0.25854\ttest-logloss:0.26139\n",
      "[2500]\ttrain-logloss:0.25822\ttest-logloss:0.26116\n",
      "[2600]\ttrain-logloss:0.25792\ttest-logloss:0.26095\n",
      "[2700]\ttrain-logloss:0.25762\ttest-logloss:0.26073\n",
      "[2800]\ttrain-logloss:0.25732\ttest-logloss:0.26052\n",
      "[2900]\ttrain-logloss:0.25704\ttest-logloss:0.26032\n",
      "[3000]\ttrain-logloss:0.25675\ttest-logloss:0.26011\n",
      "[3100]\ttrain-logloss:0.25647\ttest-logloss:0.25991\n",
      "[3200]\ttrain-logloss:0.25620\ttest-logloss:0.25972\n",
      "[3300]\ttrain-logloss:0.25591\ttest-logloss:0.25952\n",
      "[3400]\ttrain-logloss:0.25563\ttest-logloss:0.25931\n",
      "[3500]\ttrain-logloss:0.25538\ttest-logloss:0.25913\n",
      "[3600]\ttrain-logloss:0.25513\ttest-logloss:0.25896\n",
      "[3700]\ttrain-logloss:0.25487\ttest-logloss:0.25879\n",
      "[3800]\ttrain-logloss:0.25462\ttest-logloss:0.25861\n",
      "[3900]\ttrain-logloss:0.25437\ttest-logloss:0.25843\n",
      "[4000]\ttrain-logloss:0.25411\ttest-logloss:0.25825\n",
      "[4100]\ttrain-logloss:0.25386\ttest-logloss:0.25807\n",
      "[4200]\ttrain-logloss:0.25362\ttest-logloss:0.25790\n",
      "[4300]\ttrain-logloss:0.25338\ttest-logloss:0.25775\n",
      "[4400]\ttrain-logloss:0.25314\ttest-logloss:0.25759\n",
      "[4500]\ttrain-logloss:0.25292\ttest-logloss:0.25743\n",
      "[4600]\ttrain-logloss:0.25267\ttest-logloss:0.25726\n",
      "[4700]\ttrain-logloss:0.25244\ttest-logloss:0.25710\n",
      "[4800]\ttrain-logloss:0.25222\ttest-logloss:0.25696\n",
      "[4900]\ttrain-logloss:0.25199\ttest-logloss:0.25681\n",
      "[5000]\ttrain-logloss:0.25176\ttest-logloss:0.25666\n",
      "[5100]\ttrain-logloss:0.25154\ttest-logloss:0.25651\n",
      "[5200]\ttrain-logloss:0.25132\ttest-logloss:0.25635\n",
      "[5300]\ttrain-logloss:0.25110\ttest-logloss:0.25622\n",
      "[5400]\ttrain-logloss:0.25088\ttest-logloss:0.25607\n",
      "[5500]\ttrain-logloss:0.25065\ttest-logloss:0.25591\n",
      "[5600]\ttrain-logloss:0.25044\ttest-logloss:0.25578\n",
      "[5700]\ttrain-logloss:0.25023\ttest-logloss:0.25563\n",
      "[5800]\ttrain-logloss:0.25001\ttest-logloss:0.25549\n",
      "[5900]\ttrain-logloss:0.24980\ttest-logloss:0.25535\n",
      "[6000]\ttrain-logloss:0.24959\ttest-logloss:0.25522\n",
      "[6100]\ttrain-logloss:0.24939\ttest-logloss:0.25509\n",
      "[6200]\ttrain-logloss:0.24918\ttest-logloss:0.25495\n",
      "[6300]\ttrain-logloss:0.24898\ttest-logloss:0.25481\n",
      "[6400]\ttrain-logloss:0.24878\ttest-logloss:0.25469\n",
      "[6500]\ttrain-logloss:0.24858\ttest-logloss:0.25455\n",
      "[6600]\ttrain-logloss:0.24836\ttest-logloss:0.25441\n",
      "[6700]\ttrain-logloss:0.24816\ttest-logloss:0.25427\n",
      "[6800]\ttrain-logloss:0.24796\ttest-logloss:0.25415\n",
      "[6900]\ttrain-logloss:0.24776\ttest-logloss:0.25401\n",
      "[7000]\ttrain-logloss:0.24756\ttest-logloss:0.25387\n",
      "[7100]\ttrain-logloss:0.24737\ttest-logloss:0.25375\n",
      "[7200]\ttrain-logloss:0.24718\ttest-logloss:0.25362\n",
      "[7300]\ttrain-logloss:0.24698\ttest-logloss:0.25349\n",
      "[7400]\ttrain-logloss:0.24678\ttest-logloss:0.25337\n",
      "[7500]\ttrain-logloss:0.24659\ttest-logloss:0.25325\n",
      "[7600]\ttrain-logloss:0.24640\ttest-logloss:0.25312\n",
      "[7700]\ttrain-logloss:0.24621\ttest-logloss:0.25299\n",
      "[7800]\ttrain-logloss:0.24603\ttest-logloss:0.25288\n",
      "[7900]\ttrain-logloss:0.24585\ttest-logloss:0.25277\n",
      "[8000]\ttrain-logloss:0.24565\ttest-logloss:0.25264\n",
      "[8100]\ttrain-logloss:0.24547\ttest-logloss:0.25253\n",
      "[8200]\ttrain-logloss:0.24529\ttest-logloss:0.25241\n",
      "[8300]\ttrain-logloss:0.24510\ttest-logloss:0.25229\n",
      "[8400]\ttrain-logloss:0.24492\ttest-logloss:0.25216\n",
      "[8500]\ttrain-logloss:0.24475\ttest-logloss:0.25206\n",
      "[8600]\ttrain-logloss:0.24456\ttest-logloss:0.25195\n",
      "[8700]\ttrain-logloss:0.24438\ttest-logloss:0.25183\n",
      "[8800]\ttrain-logloss:0.24420\ttest-logloss:0.25172\n",
      "[8900]\ttrain-logloss:0.24402\ttest-logloss:0.25160\n",
      "[9000]\ttrain-logloss:0.24385\ttest-logloss:0.25150\n",
      "[9100]\ttrain-logloss:0.24368\ttest-logloss:0.25139\n",
      "[9200]\ttrain-logloss:0.24351\ttest-logloss:0.25128\n",
      "[9300]\ttrain-logloss:0.24333\ttest-logloss:0.25117\n",
      "[9400]\ttrain-logloss:0.24317\ttest-logloss:0.25107\n",
      "[9500]\ttrain-logloss:0.24299\ttest-logloss:0.25096\n",
      "[9600]\ttrain-logloss:0.24282\ttest-logloss:0.25086\n",
      "[9700]\ttrain-logloss:0.24266\ttest-logloss:0.25076\n",
      "[9800]\ttrain-logloss:0.24249\ttest-logloss:0.25065\n",
      "[9900]\ttrain-logloss:0.24232\ttest-logloss:0.25054\n",
      "[9998]\ttrain-logloss:0.24215\ttest-logloss:0.25044\n",
      "Kaggle Metric= 0.732506986966537 \n",
      "\n",
      "#########################\n",
      "### Fold 5\n",
      "### Train size 4425161 Valid size 1106290\n",
      "### Training with 100% fold data...\n",
      "#########################\n",
      "[0]\ttrain-logloss:0.66626\ttest-logloss:0.66627\n",
      "[100]\ttrain-logloss:0.28692\ttest-logloss:0.28764\n",
      "[200]\ttrain-logloss:0.27680\ttest-logloss:0.27769\n",
      "[300]\ttrain-logloss:0.27285\ttest-logloss:0.27385\n",
      "[400]\ttrain-logloss:0.27054\ttest-logloss:0.27165\n",
      "[500]\ttrain-logloss:0.26889\ttest-logloss:0.27009\n",
      "[600]\ttrain-logloss:0.26766\ttest-logloss:0.26895\n",
      "[700]\ttrain-logloss:0.26667\ttest-logloss:0.26803\n",
      "[800]\ttrain-logloss:0.26582\ttest-logloss:0.26727\n",
      "[900]\ttrain-logloss:0.26506\ttest-logloss:0.26659\n",
      "[1000]\ttrain-logloss:0.26439\ttest-logloss:0.26601\n",
      "[1100]\ttrain-logloss:0.26378\ttest-logloss:0.26548\n",
      "[1200]\ttrain-logloss:0.26324\ttest-logloss:0.26503\n",
      "[1300]\ttrain-logloss:0.26276\ttest-logloss:0.26463\n",
      "[1400]\ttrain-logloss:0.26229\ttest-logloss:0.26425\n",
      "[1500]\ttrain-logloss:0.26186\ttest-logloss:0.26390\n",
      "[1600]\ttrain-logloss:0.26143\ttest-logloss:0.26356\n",
      "[1700]\ttrain-logloss:0.26100\ttest-logloss:0.26322\n",
      "[1800]\ttrain-logloss:0.26060\ttest-logloss:0.26289\n",
      "[1900]\ttrain-logloss:0.26022\ttest-logloss:0.26259\n",
      "[2000]\ttrain-logloss:0.25985\ttest-logloss:0.26232\n",
      "[2100]\ttrain-logloss:0.25949\ttest-logloss:0.26204\n",
      "[2200]\ttrain-logloss:0.25916\ttest-logloss:0.26179\n",
      "[2300]\ttrain-logloss:0.25883\ttest-logloss:0.26155\n",
      "[2400]\ttrain-logloss:0.25850\ttest-logloss:0.26130\n",
      "[2500]\ttrain-logloss:0.25818\ttest-logloss:0.26105\n",
      "[2600]\ttrain-logloss:0.25786\ttest-logloss:0.26082\n",
      "[2700]\ttrain-logloss:0.25756\ttest-logloss:0.26060\n",
      "[2800]\ttrain-logloss:0.25725\ttest-logloss:0.26037\n",
      "[2900]\ttrain-logloss:0.25697\ttest-logloss:0.26016\n",
      "[3000]\ttrain-logloss:0.25669\ttest-logloss:0.25996\n",
      "[3100]\ttrain-logloss:0.25642\ttest-logloss:0.25977\n",
      "[3200]\ttrain-logloss:0.25614\ttest-logloss:0.25956\n",
      "[3300]\ttrain-logloss:0.25587\ttest-logloss:0.25937\n",
      "[3400]\ttrain-logloss:0.25561\ttest-logloss:0.25919\n",
      "[3500]\ttrain-logloss:0.25534\ttest-logloss:0.25900\n",
      "[3600]\ttrain-logloss:0.25508\ttest-logloss:0.25881\n",
      "[3700]\ttrain-logloss:0.25483\ttest-logloss:0.25864\n",
      "[3800]\ttrain-logloss:0.25456\ttest-logloss:0.25844\n",
      "[3900]\ttrain-logloss:0.25430\ttest-logloss:0.25826\n",
      "[4000]\ttrain-logloss:0.25405\ttest-logloss:0.25809\n",
      "[4100]\ttrain-logloss:0.25379\ttest-logloss:0.25790\n",
      "[4200]\ttrain-logloss:0.25355\ttest-logloss:0.25773\n",
      "[4300]\ttrain-logloss:0.25332\ttest-logloss:0.25757\n",
      "[4400]\ttrain-logloss:0.25308\ttest-logloss:0.25740\n",
      "[4500]\ttrain-logloss:0.25283\ttest-logloss:0.25723\n",
      "[4600]\ttrain-logloss:0.25260\ttest-logloss:0.25707\n",
      "[4700]\ttrain-logloss:0.25237\ttest-logloss:0.25692\n",
      "[4800]\ttrain-logloss:0.25214\ttest-logloss:0.25676\n",
      "[4900]\ttrain-logloss:0.25191\ttest-logloss:0.25660\n",
      "[5000]\ttrain-logloss:0.25169\ttest-logloss:0.25646\n",
      "[5100]\ttrain-logloss:0.25147\ttest-logloss:0.25631\n",
      "[5200]\ttrain-logloss:0.25126\ttest-logloss:0.25618\n",
      "[5300]\ttrain-logloss:0.25104\ttest-logloss:0.25604\n",
      "[5400]\ttrain-logloss:0.25082\ttest-logloss:0.25589\n",
      "[5500]\ttrain-logloss:0.25060\ttest-logloss:0.25575\n",
      "[5600]\ttrain-logloss:0.25038\ttest-logloss:0.25560\n",
      "[5700]\ttrain-logloss:0.25017\ttest-logloss:0.25546\n",
      "[5800]\ttrain-logloss:0.24996\ttest-logloss:0.25532\n",
      "[5900]\ttrain-logloss:0.24975\ttest-logloss:0.25518\n",
      "[6000]\ttrain-logloss:0.24953\ttest-logloss:0.25503\n",
      "[6100]\ttrain-logloss:0.24932\ttest-logloss:0.25488\n",
      "[6200]\ttrain-logloss:0.24912\ttest-logloss:0.25476\n",
      "[6300]\ttrain-logloss:0.24892\ttest-logloss:0.25463\n",
      "[6400]\ttrain-logloss:0.24872\ttest-logloss:0.25450\n",
      "[6500]\ttrain-logloss:0.24852\ttest-logloss:0.25437\n",
      "[6600]\ttrain-logloss:0.24832\ttest-logloss:0.25424\n",
      "[6700]\ttrain-logloss:0.24812\ttest-logloss:0.25411\n",
      "[6800]\ttrain-logloss:0.24792\ttest-logloss:0.25398\n",
      "[6900]\ttrain-logloss:0.24772\ttest-logloss:0.25385\n",
      "[7000]\ttrain-logloss:0.24752\ttest-logloss:0.25371\n",
      "[7100]\ttrain-logloss:0.24732\ttest-logloss:0.25358\n",
      "[7200]\ttrain-logloss:0.24713\ttest-logloss:0.25345\n",
      "[7300]\ttrain-logloss:0.24694\ttest-logloss:0.25334\n",
      "[7400]\ttrain-logloss:0.24675\ttest-logloss:0.25322\n",
      "[7500]\ttrain-logloss:0.24656\ttest-logloss:0.25309\n",
      "[7600]\ttrain-logloss:0.24637\ttest-logloss:0.25297\n",
      "[7700]\ttrain-logloss:0.24618\ttest-logloss:0.25285\n",
      "[7800]\ttrain-logloss:0.24600\ttest-logloss:0.25273\n",
      "[7900]\ttrain-logloss:0.24582\ttest-logloss:0.25261\n",
      "[8000]\ttrain-logloss:0.24562\ttest-logloss:0.25248\n",
      "[8100]\ttrain-logloss:0.24543\ttest-logloss:0.25235\n",
      "[8200]\ttrain-logloss:0.24524\ttest-logloss:0.25224\n",
      "[8300]\ttrain-logloss:0.24505\ttest-logloss:0.25211\n",
      "[8400]\ttrain-logloss:0.24487\ttest-logloss:0.25200\n",
      "[8500]\ttrain-logloss:0.24470\ttest-logloss:0.25189\n",
      "[8600]\ttrain-logloss:0.24452\ttest-logloss:0.25177\n",
      "[8700]\ttrain-logloss:0.24434\ttest-logloss:0.25165\n",
      "[8800]\ttrain-logloss:0.24417\ttest-logloss:0.25154\n",
      "[8900]\ttrain-logloss:0.24400\ttest-logloss:0.25145\n",
      "[9000]\ttrain-logloss:0.24381\ttest-logloss:0.25133\n",
      "[9100]\ttrain-logloss:0.24364\ttest-logloss:0.25121\n",
      "[9200]\ttrain-logloss:0.24346\ttest-logloss:0.25110\n",
      "[9300]\ttrain-logloss:0.24329\ttest-logloss:0.25100\n",
      "[9400]\ttrain-logloss:0.24313\ttest-logloss:0.25090\n",
      "[9500]\ttrain-logloss:0.24295\ttest-logloss:0.25079\n",
      "[9600]\ttrain-logloss:0.24278\ttest-logloss:0.25069\n",
      "[9700]\ttrain-logloss:0.24261\ttest-logloss:0.25059\n",
      "[9800]\ttrain-logloss:0.24245\ttest-logloss:0.25049\n",
      "[9900]\ttrain-logloss:0.24228\ttest-logloss:0.25039\n",
      "[9998]\ttrain-logloss:0.24212\ttest-logloss:0.25029\n",
      "Kaggle Metric= 0.7325460221576044 \n",
      "\n",
      "#########################\n",
      "OVERAL CV Kaggle Metric =  0.7331748923582305\n"
     ]
    }
   ],
   "source": [
    "mlflow.autolog()\n",
    "importances = []\n",
    "oof = []\n",
    "TRAIN_SUBSAMPLE = 1.0\n",
    "\n",
    "skf = KFold(n_splits = 5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train.target)):\n",
    "\n",
    "    if TRAIN_SUBSAMPLE<1.0:\n",
    "        np.random.seed(42)\n",
    "        train_idx = np.random.choice(train_idx, \n",
    "                       int(len(train_idx)*TRAIN_SUBSAMPLE), replace=False)\n",
    "        np.random.seed(None)\n",
    "        \n",
    "    print('#'*25)\n",
    "    print('### Fold',fold+1)\n",
    "    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n",
    "    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n",
    "    print('#'*25)\n",
    "\n",
    "    X_train = train.loc[train_idx, FEATURES]\n",
    "    y_train = train.loc[train_idx, 'target']\n",
    "    X_valid = train.loc[valid_idx, FEATURES]\n",
    "    y_valid = train.loc[valid_idx, 'target']\n",
    "\n",
    "    # batch_size = 200000\n",
    "    # model = None\n",
    "    # for start in range(0, len(X_train), batch_size):\n",
    "\n",
    "    dtrain=xgb.DMatrix(X_train, \n",
    "                        y_train)\n",
    "    del X_train, y_train\n",
    "    gc.collect()\n",
    "    d_valid = xgb.DMatrix(X_valid, \n",
    "                        y_valid)\n",
    "    del X_valid\n",
    "    gc.collect()\n",
    "    model = xgb.train(\n",
    "    **xgb_params,\n",
    "    dtrain=dtrain,\n",
    "    evals=[(dtrain, 'train'), (d_valid, 'test')],\n",
    "    num_boost_round= 9999,\n",
    "    early_stopping_rounds = 100,\n",
    "    verbose_eval= 100\n",
    "                                \n",
    "    )\n",
    "\n",
    "    model.save_model(f'../models/XGB_V_fold{fold}.xgb')\n",
    "    mlflow.xgboost.log_model(model, \"XGBClassifier\")\n",
    "\n",
    "    dd = model.get_score(importance_type='weight')\n",
    "    df= pd.DataFrame({'feature':dd.keys(), f'importance_{fold}':dd.values()})\n",
    "    importances.append(df)\n",
    "    \n",
    "    oof_preds = model.predict(d_valid)\n",
    "    acc = amex_metric(y_valid.values, oof_preds)\n",
    "    mlflow.log_metric(\"Kaggle Metric for XGBClassifier\", acc)\n",
    "\n",
    "    print(\"Kaggle Metric=\", acc,'\\n')\n",
    "\n",
    "    df = train.loc[valid_idx, ['customer_ID', 'target']].copy()\n",
    "    df['oof_pred']= oof_preds\n",
    "    oof.append(df)\n",
    "\n",
    "    del   dd, df\n",
    "    del  d_valid, model\n",
    "\n",
    "print('#'*25)\n",
    "oof = pd.concat(oof, axis=0, ignore_index=True).set_index('customer_ID')\n",
    "acc= amex_metric(oof.target.values, oof.oof_pred.values)\n",
    "print('OVERAL CV Kaggle Metric = ', acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting MLFlow\n",
    "experiment_name = \"LightGBM\"\n",
    "try:\n",
    "    exp_id = mlflow.create_experiment(name=experiment_name)\n",
    "except Exception as e:\n",
    "    exp_id = mlflow.get_experiment_by_name(experiment_name).experiment_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True\n",
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting': 'dart',\n",
    "    'seed': 42,\n",
    "    'num_leaves': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.20,\n",
    "    'bagging_freq': 10,\n",
    "    'bagging_fraction': 0.50,\n",
    "    'n_jobs': -1,\n",
    "    'lambda_l2': 2,\n",
    "    'min_data_in_leaf': 40,\n",
    "    'device_type': 'gpu',\n",
    "    'max_bin': 64,\n",
    "\n",
    "    }\n",
    "# Create a numpy array to store test predictions\n",
    "#test_predictions = np.zeros(len(test))\n",
    "# Create a numpy array to store out of folds predictions\n",
    "oof_predictions = np.zeros(len(train))\n",
    "skf = KFold(n_splits = 5, shuffle=True, random_state=42)\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train.target)):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {len(FEATURES)} features...')\n",
    "    x_train, x_val = train[FEATURES].iloc[train_idx], train[FEATURES].iloc[valid_idx]\n",
    "    y_train, y_val = train['target'].iloc[train_idx], train['target'].iloc[valid_idx]\n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_valid = lgb.Dataset(x_val, y_val)\n",
    "    model = lgb.train(\n",
    "        params = params,\n",
    "        train_set = lgb_train,\n",
    "        num_boost_round = 10500,\n",
    "        valid_sets = [lgb_train, lgb_valid],\n",
    "        early_stopping_rounds = 1500,\n",
    "        verbose_eval = 500,\n",
    "        feval = lgb_amex_metric\n",
    "        )\n",
    "    # Save best model\n",
    "    pickle.dump(model, open(f'../models/LGBM_fold{fold}.pkl','wb'))\n",
    "    # Predict validation\n",
    "    val_pred = model.predict(x_val)\n",
    "    # Add to out of folds array\n",
    "    oof_predictions[valid_idx] = val_pred\n",
    "    # Predict the test set\n",
    "    #test_pred = model.predict(test[FEATURES])\n",
    "    #test_predictions += test_pred / 5\n",
    "    # Compute fold metric\n",
    "    score = amex_metric(y_val, val_pred)\n",
    "    print(f'Our fold {fold} CV score is {score}')\n",
    "    mlflow.log_metric(\"Kaggle Metric for LightGbm\", acc)\n",
    "    mlflow.lightgbm.log_model(model, f\"{Model}\")\n",
    "    del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "    gc.collect()\n",
    "# Compute out of folds metric\n",
    "score = amex_metric(train[target], oof_predictions)\n",
    "print(f'Our out of folds CV score is {score}')\n",
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[target], 'prediction': oof_predictions})\n",
    "oof_df.to_csv(f'/content/drive/MyDrive/Amex/OOF/oof_lgbm_dart_baseline_5fold_seed42.csv', index = False)\n",
    "# Create a dataframe to store test prediction\n",
    "# test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "# test_df.to_csv(f'/content/drive/MyDrive/Amex/Predictions/test_lgbm_dart_baseline_fold_5_seed42.csv', index = False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fddb47bc9764f917e582b0801b6a9ae07a3476d8133832258babead972bf3eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
