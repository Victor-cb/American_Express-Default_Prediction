{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main notebook for model train and tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "\n",
    "train = pd.read_parquet(\"../data/train_woe_balanced.parquet\")\n",
    "train = train[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('WOE_target',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES = train.columns.to_list()\n",
    "FEATURES.remove(\"target\")\n",
    "FEATURES = FEATURES[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Competition metric\n",
    "def amex_metric(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Parameters\n",
    "\n",
    "# xgb_params = {\n",
    "#     'max_depth':4,\n",
    "#     'booster': 'dart',\n",
    "#     'alpha': 0.1,\n",
    "#     'learning_rate':0.035,\n",
    "#     'subsample': 0.8,\n",
    "#     'colsample_bytree':0.6,\n",
    "#     'eval_metric': 'logloss',\n",
    "#     'objective':'binary:logistic',\n",
    "#     'tree_method':'gpu_hist',\n",
    "#     'predictor':'gpu_predictor',\n",
    "#     'random_state':42\n",
    "# }\n",
    "\n",
    "xgb_params = {\n",
    "        'num_leaves': 10,\n",
    "        'max_bin': 127,\n",
    "        'min_data_in_leaf': 11,\n",
    "        'learning_rate': 0.02,\n",
    "        'min_sum_hessian_in_leaf': 0.00245,\n",
    "        'bagging_fraction': 1.0, \n",
    "        'bagging_freq': 5, \n",
    "        'feature_fraction': 0.05,\n",
    "        'lambda_l1': 4.972,\n",
    "        'lambda_l2': 2.276,\n",
    "        'min_gain_to_split': 0.65,\n",
    "        'max_depth': 14,\n",
    "        'save_binary': True,\n",
    "        'seed': 1337,\n",
    "        'feature_fraction_seed': 1337,\n",
    "        'bagging_seed': 1337,\n",
    "        'drop_seed': 1337,\n",
    "        'data_random_seed': 1337,\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'dart',\n",
    "        'verbose': 1,\n",
    "        'is_unbalance': True,\n",
    "        'boost_from_average': False,\n",
    "        'device': 'gpu',\n",
    "        'gpu_platform_id': 0,\n",
    "        'gpu_device_id': 0\n",
    "        }\n",
    "\n",
    "reg_log_params={\n",
    "        'penalty': 'l2',\n",
    "        'max_iter': 200,\n",
    "        'warm_start': True,\n",
    "        'n_jobs': 1,\n",
    "            \n",
    "                }\n",
    "fores_params={\n",
    "        'bootstrap': True,\n",
    "        'criterion': 'mse',\n",
    "        'max_depth': None,\n",
    "        'max_features': 'auto',\n",
    "        'max_leaf_nodes': None,\n",
    "        'min_impurity_decrease': 0.0,\n",
    "        'min_impurity_split': None,\n",
    "        'min_samples_leaf': 1,\n",
    "        'min_samples_split': 2,\n",
    "        'min_weight_fraction_leaf': 0.0,\n",
    "        'n_estimators': 10,\n",
    "        'n_jobs': -1,\n",
    "        'oob_score': False,\n",
    "        'random_state': 42,\n",
    "        'verbose': 0,\n",
    "        'warm_start': False\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "models= {\n",
    "        \"reg_log\":LogisticRegression(reg_log_params),\n",
    "        \"xgb\": xgb.XGBClassifier(xgb_params),\n",
    "        \"forest\": RandomForestClassifier(fores_params)\n",
    "}\n",
    "\n",
    "# VERSION NAME FOR SAVED MODEL FILES\n",
    "VER = '03'\n",
    "\n",
    "# TRAIN RANDOM SEED\n",
    "SEED = 42\n",
    "\n",
    "# FILL NAN VALUE\n",
    "NAN_VALUE = -127 # will fit in int8\n",
    "\n",
    "# FOLDS PER MODEL\n",
    "FOLDS = 5\n",
    "\n",
    "# TRAIN FOLD\n",
    "#TRAIN_PATH = \"../data/processed/train_woe_balanced.parquet\"\n",
    "\n",
    "importances = []\n",
    "oof = []\n",
    "TRAIN_SUBSAMPLE = 1.0\n",
    "\n",
    "skf = KFold(n_splits = FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train.target)):\n",
    "        for k in models.v:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(penalty={'max_iter': 200, 'n_jobs': 1, 'penalty': 'l2',\n",
      "                            'warm_start': True})\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_s...\n",
      "                         'feature_fraction_seed': 1337, 'gpu_device_id': 0,\n",
      "                         'gpu_platform_id': 0, 'is_unbalance': True,\n",
      "                         'lambda_l1': 4.972, 'lambda_l2': 2.276,\n",
      "                         'learning_rate': 0.02, 'max_bin': 127, 'max_depth': 14,\n",
      "                         'min_data_in_leaf': 11, 'min_gain_to_split': 0.65,\n",
      "                         'min_sum_hessian_in_leaf': 0.00245, 'num_leaves': 10,\n",
      "                         'objective': 'binary', 'save_binary': True,\n",
      "                         'seed': 1337, 'verbose': 1},\n",
      "              predictor=None, random_state=None, reg_alpha=None, ...)\n",
      "RandomForestClassifier(n_estimators={'bootstrap': True, 'criterion': 'mse',\n",
      "                                     'max_depth': None, 'max_features': 'auto',\n",
      "                                     'max_leaf_nodes': None,\n",
      "                                     'min_impurity_decrease': 0.0,\n",
      "                                     'min_impurity_split': None,\n",
      "                                     'min_samples_leaf': 1,\n",
      "                                     'min_samples_split': 2,\n",
      "                                     'min_weight_fraction_leaf': 0.0,\n",
      "                                     'n_estimators': 10, 'n_jobs': -1,\n",
      "                                     'oob_score': False, 'random_state': 42,\n",
      "                                     'verbose': 0, 'warm_start': False})\n"
     ]
    }
   ],
   "source": [
    "for k in models.values():\n",
    "    print(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('rapidsai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b42f6a117c4327c96e827345377b7371732c816391a5566011ece4de55706102"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
