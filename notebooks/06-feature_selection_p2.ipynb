{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"../data/processed/train_fs.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data...\n",
      "shape of data: (5531451, 168)\n"
     ]
    }
   ],
   "source": [
    "def read_file(path = '', usecols = None):\n",
    "    # LOAD DATAFRAME\n",
    "    if usecols is not None: df = pd.read_parquet(path, columns=usecols)\n",
    "    else: df = pd.read_parquet(path)\n",
    "    # REDUCE DTYPE FOR CUSTOMER AND DATE\n",
    "    df.S_2 = pd.to_datetime( df.S_2 )\n",
    "    # SORT BY CUSTOMER AND DATE (so agg('last') works correctly)\n",
    "    df = df.sort_values(['customer_ID','S_2'])\n",
    "    df = df.reset_index(drop=True)\n",
    "    # FILL NAN\n",
    "    df = df.fillna(-127) \n",
    "    print('shape of data:', df.shape)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print('Reading train data...')\n",
    "TRAIN_PATH = '../data/processed/train_fs.parquet'\n",
    "train = read_file(path = TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 166 features!\n"
     ]
    }
   ],
   "source": [
    "# FEATURES\n",
    "FEATURES = train.columns[2:]\n",
    "print(f'There are {len(FEATURES)} features!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after engineering (458913, 808)\n"
     ]
    }
   ],
   "source": [
    "def process_and_feature_engineer(df):\n",
    "    # FEATURE ENGINEERING FROM \n",
    "    # https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
    "    all_cols = [c for c in list(df.columns) if c not in ['customer_ID','S_2']]\n",
    "    cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
    "    num_features = [col for col in all_cols if col not in cat_features]\n",
    "\n",
    "    test_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "\n",
    "    test_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "\n",
    "    df = pd.concat([test_num_agg, test_cat_agg], axis=1)\n",
    "    del test_num_agg, test_cat_agg\n",
    "    print('shape after engineering', df.shape )\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = process_and_feature_engineer(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First set of features added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet(\"../data/processed/train_feature.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature WOE && IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iv_woe(data, target, bins=10, show_woe=False):\n",
    "    \n",
    "    #Empty Dataframe\n",
    "    newDF,woeDF = pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    #Extract Column Names\n",
    "    cols = data.columns\n",
    "    \n",
    "    #Run WOE and IV on all the independent variables\n",
    "    for ivars in cols[~cols.isin([target])]:\n",
    "        if (data[ivars].dtype.kind in 'bifc') and (len(np.unique(data[ivars]))>10):\n",
    "            binned_x = pd.qcut(data[ivars], bins,  duplicates='drop')\n",
    "            d0 = pd.DataFrame({'x': binned_x, 'y': data[target]})\n",
    "        else:\n",
    "            d0 = pd.DataFrame({'x': data[ivars], 'y': data[target]})\n",
    "\n",
    "        \n",
    "        # Calculate the number of events in each group (bin)\n",
    "        d = d0.groupby(\"x\", as_index=False).agg({\"y\": [\"count\", \"sum\"]})\n",
    "        d.columns = ['Cutoff', 'N', 'Events']\n",
    "        \n",
    "        # Calculate % of events in each group.\n",
    "        d['% of Events'] = np.maximum(d['Events'], 0.5) / d['Events'].sum()\n",
    "\n",
    "        # Calculate the non events in each group.\n",
    "        d['Non-Events'] = d['N'] - d['Events']\n",
    "        # Calculate % of non events in each group.\n",
    "        d['% of Non-Events'] = np.maximum(d['Non-Events'], 0.5) / d['Non-Events'].sum()\n",
    "\n",
    "        # Calculate WOE by taking natural log of division of % of non-events and % of events\n",
    "        d['WoE'] = np.log(d['% of Events']/d['% of Non-Events'])\n",
    "        d['IV'] = d['WoE'] * (d['% of Events'] - d['% of Non-Events'])\n",
    "        d.insert(loc=0, column='Variable', value=ivars)\n",
    "        print(\"Information value of \" + ivars + \" is \" + str(round(d['IV'].sum(),6)))\n",
    "        temp =pd.DataFrame({\"Variable\" : [ivars], \"IV\" : [d['IV'].sum()]}, columns = [\"Variable\", \"IV\"])\n",
    "        newDF=pd.concat([newDF,temp], axis=0)\n",
    "        woeDF=pd.concat([woeDF,d], axis=0)\n",
    "\n",
    "        #Show WOE Table\n",
    "        if show_woe == True:\n",
    "            print(d)\n",
    "    return newDF, woeDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information value of customer_ID is 6.100698\n",
      "Information value of S_2 is 0.008395\n",
      "Information value of P_2 is 2.982891\n",
      "Information value of D_39 is 0.10178\n",
      "Information value of B_1 is 1.291884\n",
      "Information value of B_2 is 1.289213\n",
      "Information value of R_1 is 0.603611\n",
      "Information value of S_3 is 0.836053\n",
      "Information value of D_41 is 0.290369\n",
      "Information value of B_3 is 1.332385\n",
      "Information value of D_42 is 1.575721\n",
      "Information value of D_43 is 0.50723\n",
      "Information value of D_44 is 1.41223\n",
      "Information value of B_4 is 1.16503\n",
      "Information value of D_45 is 0.675468\n",
      "Information value of B_5 is 0.323848\n",
      "Information value of R_2 is 0.315512\n",
      "Information value of D_46 is 0.335184\n",
      "Information value of D_47 is 0.500697\n",
      "Information value of D_48 is 1.971191\n",
      "Information value of D_49 is 0.0\n",
      "Information value of B_6 is 1.495013\n",
      "Information value of B_7 is 1.576316\n",
      "Information value of B_8 is 0.470344\n",
      "Information value of D_50 is 0.523316\n",
      "Information value of D_51 is 0.576941\n",
      "Information value of B_9 is 1.442702\n",
      "Information value of R_3 is 0.387472\n",
      "Information value of D_52 is 0.784062\n",
      "Information value of P_3 is 0.442689\n",
      "Information value of B_10 is 1.541482\n",
      "Information value of D_53 is 0.451527\n",
      "Information value of S_5 is 0.196784\n",
      "Information value of B_11 is 1.206137\n",
      "Information value of S_6 is 0.057305\n",
      "Information value of D_54 is 0.0\n",
      "Information value of R_4 is 0.227856\n",
      "Information value of B_12 is 0.245049\n",
      "Information value of S_8 is 0.281663\n",
      "Information value of D_56 is 0.366383\n",
      "Information value of B_13 is 0.184285\n",
      "Information value of R_5 is 0.0\n",
      "Information value of D_58 is 1.187391\n",
      "Information value of S_9 is 0.028229\n",
      "Information value of B_14 is 0.537021\n",
      "Information value of D_59 is 0.200892\n",
      "Information value of D_60 is 0.494721\n",
      "Information value of D_61 is 1.659157\n",
      "Information value of S_11 is 0.069861\n",
      "Information value of D_62 is 1.533271\n",
      "Information value of D_63 is 0.042769\n",
      "Information value of D_64 is 0.214947\n",
      "Information value of D_65 is 0.0\n",
      "Information value of B_16 is 0.905794\n",
      "Information value of B_17 is 0.381477\n",
      "Information value of B_19 is 0.859619\n",
      "Information value of D_66 is 0.017383\n",
      "Information value of D_68 is 0.203751\n",
      "Information value of S_12 is 0.024849\n",
      "Information value of R_6 is 0.093607\n",
      "Information value of S_13 is 0.086802\n",
      "Information value of B_21 is 0.02421\n",
      "Information value of D_69 is 0.020655\n",
      "Information value of B_22 is 0.691388\n",
      "Information value of D_70 is 0.446919\n",
      "Information value of D_71 is 0.260377\n",
      "Information value of D_72 is 0.226063\n",
      "Information value of S_15 is 0.32952\n",
      "Information value of D_73 is 0.177206\n",
      "Information value of P_4 is 0.206166\n",
      "Information value of D_76 is 1.057218\n",
      "Information value of B_24 is 0.028385\n",
      "Information value of R_7 is 0.0\n",
      "Information value of B_25 is 0.579562\n",
      "Information value of B_26 is 0.069764\n",
      "Information value of D_78 is 0.399997\n",
      "Information value of D_79 is 0.236283\n",
      "Information value of R_8 is 0.0\n",
      "Information value of R_9 is 0.0\n",
      "Information value of S_16 is 0.024191\n",
      "Information value of D_80 is 0.015185\n",
      "Information value of R_10 is 0.0\n",
      "Information value of R_11 is 0.0\n",
      "Information value of B_27 is 3.1e-05\n",
      "Information value of D_81 is 0.203317\n",
      "Information value of D_82 is 0.02171\n",
      "Information value of S_17 is 0.001402\n",
      "Information value of R_12 is 0.0\n",
      "Information value of B_28 is 0.614213\n",
      "Information value of R_13 is 0.0\n",
      "Information value of D_83 is 0.03971\n",
      "Information value of R_14 is 0.0\n",
      "Information value of R_15 is 0.073195\n",
      "Information value of D_84 is 0.275178\n",
      "Information value of R_16 is 0.0\n",
      "Information value of B_29 is 0.005402\n",
      "Information value of B_30 is 0.601625\n",
      "Information value of S_18 is 0.000557\n",
      "Information value of D_86 is 0.034015\n",
      "Information value of D_87 is 0.00688\n",
      "Information value of R_17 is 0.0\n",
      "Information value of R_18 is 0.0\n",
      "Information value of D_88 is 0.380604\n",
      "Information value of B_31 is 0.01586\n",
      "Information value of S_19 is 0.000166\n",
      "Information value of R_19 is 0.04507\n",
      "Information value of B_32 is 0.045673\n",
      "Information value of S_20 is 0.078385\n",
      "Information value of R_20 is 0.103546\n",
      "Information value of R_21 is 0.104355\n",
      "Information value of D_89 is 0.085962\n",
      "Information value of R_22 is 0.018126\n",
      "Information value of R_23 is 0.001149\n",
      "Information value of D_91 is 0.158069\n",
      "Information value of D_92 is 0.241085\n",
      "Information value of D_93 is 0.00989\n",
      "Information value of D_94 is 0.053633\n",
      "Information value of R_24 is 0.101386\n",
      "Information value of R_25 is 0.017447\n",
      "Information value of D_96 is 0.026107\n",
      "Information value of S_22 is 0.626038\n",
      "Information value of S_23 is 0.44102\n",
      "Information value of S_25 is 0.489884\n",
      "Information value of S_26 is 0.078793\n",
      "Information value of D_102 is 0.086331\n",
      "Information value of D_103 is 0.087148\n",
      "Information value of D_105 is 0.009431\n",
      "Information value of D_106 is 0.0\n",
      "Information value of B_36 is 0.000824\n",
      "Information value of R_26 is 0.332928\n",
      "Information value of R_27 is 0.422139\n",
      "Information value of B_38 is 1.279814\n",
      "Information value of D_108 is 0.0\n",
      "Information value of D_109 is 0.004611\n",
      "Information value of D_110 is 0.075769\n",
      "Information value of B_39 is 0.043415\n",
      "Information value of D_112 is 0.204157\n",
      "Information value of B_40 is 1.20772\n",
      "Information value of S_27 is 0.305437\n",
      "Information value of D_113 is 0.11342\n",
      "Information value of D_114 is 0.209452\n",
      "Information value of D_115 is 0.201979\n",
      "Information value of D_116 is 0.032382\n",
      "Information value of D_117 is 0.18646\n",
      "Information value of D_118 is 0.184151\n",
      "Information value of D_120 is 0.194074\n",
      "Information value of D_121 is 0.167923\n",
      "Information value of D_122 is 0.171631\n",
      "Information value of D_123 is 0.019095\n",
      "Information value of D_124 is 0.04416\n",
      "Information value of D_125 is 0.02328\n",
      "Information value of D_126 is 0.048179\n",
      "Information value of D_127 is 0.386721\n",
      "Information value of D_128 is 0.134154\n",
      "Information value of D_129 is 0.106281\n",
      "Information value of B_41 is 0.042585\n",
      "Information value of B_42 is 2.520457\n",
      "Information value of D_130 is 0.095898\n",
      "Information value of D_133 is 0.143472\n",
      "Information value of R_28 is 0.003221\n",
      "Information value of D_134 is 0.030054\n",
      "Information value of D_135 is 0.108593\n",
      "Information value of D_139 is 0.083562\n",
      "Information value of D_140 is 0.063495\n",
      "Information value of D_142 is 0.043756\n",
      "Information value of D_144 is 0.000347\n",
      "Information value of D_145 is 0.077741\n"
     ]
    }
   ],
   "source": [
    "newdf, woedf = iv_woe(data=train, target='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "class CategoricalFeature():\n",
    "    def __init__(self, df, feature):\n",
    "        self.df = df\n",
    "        self.feature = feature\n",
    "\n",
    "    @property\n",
    "    def df_lite(self):\n",
    "        df_lite = self.df\n",
    "        df_lite['bin'] = df_lite[self.feature].fillna('MISSING')\n",
    "        return df_lite[['bin', 'target']]\n",
    "\n",
    "\n",
    "class ContinuousFeature():\n",
    "    def __init__(self, df, feature):\n",
    "        self.df = df\n",
    "        self.feature = feature\n",
    "        self.bin_min_size = int(len(self.df) * 0.05)\n",
    "\n",
    "    def __generate_bins(self, bins_num):\n",
    "        df = self.df[[self.feature, 'target']]\n",
    "        df['bin'] = pd.qcut(df[self.feature], bins_num, duplicates='drop') \\\n",
    "                    .apply(lambda x: x.left) \\\n",
    "                    .astype(float)\n",
    "        return df\n",
    "\n",
    "    def __generate_correct_bins(self, bins_max=20):\n",
    "        for bins_num in range(bins_max, 1, -1):\n",
    "            df = self.__generate_bins(bins_num)\n",
    "            df_grouped = pd.DataFrame(df.groupby('bin') \\\n",
    "                                      .agg({self.feature: 'count',\n",
    "                                            'target': 'sum'})) \\\n",
    "                                      .reset_index()\n",
    "            r, p = stats.spearmanr(df_grouped['bin'], df_grouped['target'])\n",
    "\n",
    "            if (\n",
    "                    abs(r)==1 and                                                        # check if woe for bins are monotonic\n",
    "                    df_grouped[self.feature].min() > self.bin_min_size                   # check if bin size is greater than 5%\n",
    "                    and not (df_grouped[self.feature] == df_grouped['target']).any()      # check if number of good and bad is not equal to 0\n",
    "            ):\n",
    "                break\n",
    "\n",
    "        return df\n",
    "\n",
    "    @property\n",
    "    def df_lite(self):\n",
    "        df_lite = self.__generate_correct_bins()\n",
    "        df_lite['bin'].fillna('MISSING', inplace=True)\n",
    "        return df_lite[['bin', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "class AttributeRelevance():\n",
    "    def seq_palette(self, n_colors):\n",
    "        return sns.cubehelix_palette(n_colors, start=.5, rot=-.75, reverse=True)\n",
    "\n",
    "    def bulk_iv(self, feats, iv, woe_extremes=False):\n",
    "        iv_dict = {}\n",
    "        for f in feats:\n",
    "            iv_df, iv_value = iv.calculate_iv(f)\n",
    "            if woe_extremes:\n",
    "                iv_dict[f.feature] = [iv_value, iv_df['woe'].min(), iv_df['woe'].max()]\n",
    "                cols = ['iv', 'woe_min', 'woe_max']\n",
    "            else:\n",
    "                iv_dict[f.feature] = iv_value\n",
    "                cols = ['iv']\n",
    "        df = pd.DataFrame.from_dict(iv_dict, orient='index', columns=cols)\n",
    "        return df\n",
    "\n",
    "    def bulk_stats(self, feats, s):\n",
    "        stats_dict = {}\n",
    "        for f in feats:\n",
    "            p_value, effect_size = s.calculate_chi(f)\n",
    "            stats_dict[f.feature] = [p_value, effect_size]\n",
    "        df = pd.DataFrame.from_dict(stats_dict, orient='index', columns=['p-value', 'effect_size'])\n",
    "        return df\n",
    "\n",
    "    def analyze(self, feats, iv, s=None, interpretation=False):\n",
    "        df_iv = self.bulk_iv(feats, iv).sort_values(by='iv', ascending=False)\n",
    "        if s is not None:\n",
    "            df_stats = self.bulk_stats(feats, s)\n",
    "            df_iv = df_iv.merge(df_stats, left_index=True, right_index=True)\n",
    "        if interpretation:\n",
    "            df_iv['iv_interpretation'] = df_iv['iv'].apply(iv.interpretation)\n",
    "            if s is not None:\n",
    "                df_iv['es_interpretation'] = df_iv['effect_size'].apply(s.interpretation)\n",
    "        return df_iv\n",
    "\n",
    "    def draw_iv(self, feats, iv):\n",
    "        df = self.analyze(feats, iv)\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.barplot(x=df.index, y='iv', data=df, palette=self.seq_palette(len(feats)))\n",
    "        ax.set_title('IV values')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.show()\n",
    "\n",
    "    def draw_woe_extremes(self, feats, iv):\n",
    "        df = self.bulk_iv(feats, iv, woe_extremes=True).sort_values(by='iv', ascending=False)\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.barplot(x=df.index, y='woe_min', data=df, palette=self.seq_palette(len(feats)))\n",
    "        sns.barplot(x=df.index, y='woe_max', data=df, palette=self.seq_palette(len(feats)))\n",
    "        ax.axhline(y=0, color='black', linewidth=1)\n",
    "        ax.set_title('Range of WOE values')\n",
    "        ax.set_ylabel('WOE')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.show()\n",
    "\n",
    "    def draw_woe_multiplot(self, feats, iv):\n",
    "        n = len(feats)\n",
    "        nrows = int(np.ceil(n/3))\n",
    "        fig, ax = plt.subplots(nrows=nrows, ncols=3, figsize=(15, nrows*4))\n",
    "        for i in range(n):\n",
    "            iv_df, iv_value = iv.calculate_iv(feats[i])\n",
    "            sns.barplot(x=feats[i].feature, y='woe', data=iv_df, color='#455872', ax=fig.axes[i])\n",
    "\n",
    "        for ax in fig.axes:\n",
    "            plt.sca(ax)\n",
    "            plt.xticks(rotation=50)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "class Analysis():\n",
    "    def seq_palette(self, n_colors):\n",
    "        return sns.cubehelix_palette(n_colors, start=.5, rot=-.75, reverse=True)\n",
    "\n",
    "    def group_by_feature(self, feat):\n",
    "        df = feat.df_lite \\\n",
    "                            .groupby('bin') \\\n",
    "                            .agg({'target': ['count', 'sum']}) \\\n",
    "                            .reset_index()\n",
    "        df.columns = [feat.feature, 'count', 'good']\n",
    "        df['bad'] = df['count'] - df['good']\n",
    "        return df\n",
    "\n",
    "class StatsSignificance(Analysis):\n",
    "    def calculate_chi(self, feat):\n",
    "        df = self.group_by_feature(feat)\n",
    "        df_chi = np.array(df[['good', 'bad']])\n",
    "        n = df['count'].sum()\n",
    "\n",
    "        chi = stats.chi2_contingency(df_chi)\n",
    "        cramers_v = np.sqrt(chi[0] / n)          # assume that k=2 (good, bad)\n",
    "        return chi[1], cramers_v\n",
    "\n",
    "    @staticmethod\n",
    "    def interpretation(cramers_v):\n",
    "        if cramers_v < 0.1:\n",
    "            return 'useless'\n",
    "        elif cramers_v < 0.2:\n",
    "            return 'weak'\n",
    "        elif cramers_v < 0.4:\n",
    "            return 'medium'\n",
    "        elif cramers_v < 0.6:\n",
    "            return 'strong'\n",
    "        else:\n",
    "            return 'very strong'\n",
    "\n",
    "    def interpret_chi(self, feat):\n",
    "        _, cramers_v = self.calculate_chi(feat)\n",
    "        return self.interpretation(cramers_v)\n",
    "\n",
    "    def print_chi(self, feat):\n",
    "        p_value, cramers_v = self.calculate_chi(feat)\n",
    "        print('P-value: %0.2f\\nEffect size: %0.2f' % (p_value, cramers_v))\n",
    "        print('%s is a %s predictor' % (feat.feature.capitalize(), self.interpretation(cramers_v)))\n",
    "\n",
    "\n",
    "class IV(Analysis):\n",
    "    @staticmethod\n",
    "    def __perc_share(df, group_name):\n",
    "        return df[group_name] / df[group_name].sum()\n",
    "\n",
    "    def __calculate_perc_share(self, feat):\n",
    "        df = self.group_by_feature(feat)\n",
    "        df['perc_good'] = self.__perc_share(df, 'good')\n",
    "        df['perc_bad'] = self.__perc_share(df, 'bad')\n",
    "        df['perc_diff'] = df['perc_good'] - df['perc_bad']\n",
    "        return df\n",
    "\n",
    "    def __calculate_woe(self, feat):\n",
    "        df = self.__calculate_perc_share(feat)\n",
    "        df['woe'] = np.log(df['perc_good']/df['perc_bad'])\n",
    "        df['woe'] = df['woe'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        return df\n",
    "\n",
    "    def calculate_iv(self, feat):\n",
    "        df = self.__calculate_woe(feat)\n",
    "        df['iv'] = df['perc_diff'] * df['woe']\n",
    "        return df, df['iv'].sum()\n",
    "\n",
    "    def draw_woe(self, feat):\n",
    "        iv_df, iv_value = self.calculate_iv(feat)\n",
    "        fig, ax = plt.subplots(figsize=(10,6))\n",
    "        sns.barplot(x=feat.feature, y='woe', data=iv_df, palette=self.seq_palette(len(iv_df.index)))\n",
    "        ax.set_title('WOE visualization for: ' + feat.feature)\n",
    "        plt.show()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def interpretation(iv):\n",
    "        if iv < 0.02:\n",
    "            return 'useless'\n",
    "        elif iv < 0.1:\n",
    "            return 'weak'\n",
    "        elif iv < 0.3:\n",
    "            return 'medium'\n",
    "        elif iv < 0.5:\n",
    "            return 'strong'\n",
    "        else:\n",
    "            return 'suspicious'\n",
    "\n",
    "    def interpret_iv(self, feat):\n",
    "        _, iv = self.calculate_iv(feat)\n",
    "        return self.interpretation(iv)\n",
    "\n",
    "    def print_iv(self, feat):\n",
    "        _, iv = self.calculate_iv(feat)\n",
    "        print('Information value: %0.2f' % iv)\n",
    "        print('%s is a %s predictor' % (feat.feature.capitalize(), self.interpretation(iv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "\n",
    "\n",
    "num_cols = [c for c in train.columns if c not in [cat_cols, \"customer_ID\", \"S_2\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv=IV()\n",
    "df_iv = []\n",
    "feature_iv= []\n",
    "\n",
    "def woe_iv_dataframe(df):\n",
    "   \n",
    "\n",
    "    for c in df[FEATURES].columns:\n",
    "        feats_dict={}\n",
    "        \n",
    "        if c in cat_cols:\n",
    "            feats_dict={}\n",
    "            feats_dict[c]= CategoricalFeature(df[FEATURES], c)\n",
    "            feats_dict = list(feats_dict.values())\n",
    "            iv_df, iv_value = iv.calculate_iv(feats_dict[0])\n",
    "            df_iv.append(iv_value)\n",
    "            feature_iv.append(c)\n",
    "            #iv_df.to_csv(f\"../reports/woe_iv_features/categorical_iv_woe_{c}.csv\")          \n",
    "            del feats_dict,iv_df\n",
    "        else:\n",
    "            feats_dict[c] = ContinuousFeature(df[FEATURES], c)\n",
    "            feats_dict = list(feats_dict.values())\n",
    "            iv_df, iv_value = iv.calculate_iv(feats_dict[0])\n",
    "            df_iv.append(iv_value)\n",
    "            feature_iv.append(c)\n",
    "            #iv_df.to_csv(f\"../reports/woe_iv_features/numerical_iv_woe_{c}.csv\")          \n",
    "            del feats_dict,iv_df\n",
    "    print(\"End\")\n",
    "woe_iv_dataframe(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_values_df = pd.DataFrame()\n",
    "iv_values_df[\"feature\"]= feature_iv\n",
    "iv_values_df[\"iv_value\"] = df_iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>iv_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P_2</td>\n",
       "      <td>3.003221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D_39</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B_1</td>\n",
       "      <td>1.298186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B_2</td>\n",
       "      <td>1.300355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R_1</td>\n",
       "      <td>0.206707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature  iv_value\n",
       "0     P_2  3.003221\n",
       "1    D_39  0.000000\n",
       "2     B_1  1.298186\n",
       "3     B_2  1.300355\n",
       "4     R_1  0.206707"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_values_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"C:/Users/brito/OneDrive/Documentos/1 - Data Science/3 - Projeto/04 - American Express/reports/woe_iv_features\"\n",
    "all_files=glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "li=[]\n",
    "\n",
    "for file in all_files:\n",
    "    df= pd.read_csv(file, index_col=0, header=0)\n",
    "    li.append(df) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rules For Information Value(IV)](../references/iv_values_table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uselesse predictors <0.02 IV values\n",
    "iv_drop_variables = iv_values_df[iv_values_df['iv_value']<= 0.02]['feature'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13       B_5\n",
       "38      B_13\n",
       "41       S_9\n",
       "46      S_11\n",
       "48      D_63\n",
       "57       R_6\n",
       "58      S_13\n",
       "60      D_69\n",
       "65      S_15\n",
       "88      D_83\n",
       "108     D_89\n",
       "119     S_23\n",
       "120     S_25\n",
       "121     S_26\n",
       "122    D_102\n",
       "123    D_103\n",
       "124    D_105\n",
       "128     R_27\n",
       "136     S_27\n",
       "140    D_116\n",
       "148    D_125\n",
       "149    D_126\n",
       "153     B_41\n",
       "154     B_42\n",
       "156    D_133\n",
       "160    D_139\n",
       "161    D_140\n",
       "162    D_142\n",
       "164    D_145\n",
       "Name: feature, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_values_df[(iv_values_df['iv_value']<= 0.1 ) & (iv_values_df['iv_value']>= 0.02 )]['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_values_df[iv_values_df['iv_value'] > 0.5]['feature'].to_list().append(iv_drop_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Large amount of features that are considered useless or to good to be true\n",
    "len(iv_drop_variables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9b182ac41fde53106323aa7515f1b29a8d8a34b9130befdd44270541b718f75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
